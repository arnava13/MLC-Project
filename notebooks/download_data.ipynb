{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64d05ec",
   "metadata": {},
   "source": [
    "# UHI Data Download and Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ad6e9-2a3a-4806-8e78-2db0200aa044",
   "metadata": {
    "tags": []
   },
   "source": [
    "Configured for downloading Sentinel-2b / Landsat-LST mosaics within a bounding box defined by a csv of UHI measurements\n",
    "Designed to work for NYC but can be extended to other cities. Requires ground-level intraday UHI measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fad66",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c94725a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import zipfile # For more robust unzipping\n",
    "import time\n",
    "import pystac_client\n",
    "import pystac\n",
    "import planetary_computer\n",
    "import stackstac\n",
    "\n",
    "# Imports for tile index processing\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Add the project root to the Python path to allow importing from src\n",
    "project_root = Path(os.getcwd()).parent  # Assumes notebook is in 'notebooks' subdir\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d213cf9-4623-420a-af80-3d7658873ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounds from UHI data: /home/jupyter/MLC-Project/data/NYC/uhi.csv\n",
      "Representative UHI date (from first row): 2021-07-24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuration for Data Download ---\n",
    "\n",
    "# Configure parameters for the target city (e.g., NYC)\n",
    "city_name = \"NYC\"\n",
    "\n",
    "# Time window matching original notebooks (adjust if needed)\n",
    "sentinel_time_window = \"2021-06-01/2021-09-01\"\n",
    "lst_time_window = \"2021-06-01/2021-09-01\"\n",
    "\n",
    "# Input files and general settings\n",
    "data_dir = Path(\"data\")\n",
    "abs_output_dir = project_root / data_dir\n",
    "uhi_csv = data_dir / city_name / \"uhi.csv\" # Path to UHI data\n",
    "abs_uhi_csv = project_root / uhi_csv\n",
    "# bbox_csv is no longer needed for bounds calculation\n",
    "\n",
    "if not abs_uhi_csv.exists():\n",
    "    raise FileNotFoundError(f\"UHI data CSV not found at {abs_uhi_csv}. Cannot derive bounds.\")\n",
    "print(f\"Loading bounds from UHI data: {abs_uhi_csv}\")\n",
    "uhi_df = pd.read_csv(abs_uhi_csv)\n",
    "# Check if required columns exist\n",
    "required_cols = ['Longitude', 'Latitude']\n",
    "if not all(col in uhi_df.columns for col in required_cols):\n",
    "     raise ValueError(f\"UHI CSV must contain columns: {required_cols}\")\n",
    "\n",
    "# Load bounds\n",
    "bounds = [\n",
    "    uhi_df['Longitude'].min(),\n",
    "    uhi_df['Latitude'].min(),\n",
    "    uhi_df['Longitude'].max(),\n",
    "    uhi_df['Latitude'].max()\n",
    "]\n",
    "\n",
    "# Load observation da\n",
    "first_datetime_obj = pd.to_datetime(uhi_df['datetime'].iloc[0], format='%d-%m-%Y %H:%M')\n",
    "# Format the date object into 'YYYY-MM-DD' string format\n",
    "uhi_date_str = first_datetime_obj.strftime('%Y-%m-%d')\n",
    "print(f\"Representative UHI date (from first row): {uhi_date_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a40f09-4d85-4918-9cc6-b72e94fbe493",
   "metadata": {},
   "source": [
    "## 2. Download Satellite Data for Cities\n",
    "\n",
    "Now we'll download satellite imagery data (Sentinel-2 median composites, Landsat LST medians) for specific cities and time periods derived from the UHI data timestamps. Data is saved locally for use by the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9301ef-6171-459a-97a8-46af9ee5ee3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: NYC\n",
      "Sentinel-2 Time Window: 2021-06-01/2021-09-01\n",
      "Sentinel-2 Cloud Cover Threshold: 30%\n",
      "LST Time Window: 2021-06-01/2021-09-01\n",
      "Bounds derived from uhi.csv: [np.float64(-73.99445667), np.float64(40.75879167), np.float64(-73.87945833), np.float64(40.85949667)]\n",
      "Target mosaic output path: /home/jupyter/MLC-Project/data/NYC/sat_files/sentinel_NYC_20210601_to_20210901_cloudless_mosaic.npy\n",
      "Include LST: False\n"
     ]
    }
   ],
   "source": [
    "# Import functions\n",
    "from src.ingest.get_median import create_and_save_cloudless_mosaic\n",
    "# Import the modified LST download function\n",
    "from src.ingest.create_sat_tensor_files import download_single_lst_median\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Parameters for Cloudless Mosaic (matching Sentinel2_GeoTIFF.ipynb)\n",
    "mosaic_bands = [\"B02\", \"B03\", \"B04\", \"B08\"] # RGB+NIR for Clay compatibility\n",
    "mosaic_resolution_m = 10\n",
    "mosaic_cloud_cover = 30\n",
    "\n",
    "# Parameters for LST Median (matching Landsat_LST.ipynb)\n",
    "include_lst = False         # Whether to download LST\n",
    "lst_resolution_m = 30      # Native resolution for Landsat LST\n",
    "\n",
    "# Generate output path for the mosaic based on the new time window\n",
    "start_dt_str = sentinel_time_window.split('/')[0].replace('-','')\n",
    "end_dt_str = sentinel_time_window.split('/')[1].replace('-','')\n",
    "band_str = \"_\".join(mosaic_bands)\n",
    "cloudless_mosaic_filename = f\"sentinel_{city_name}_{start_dt_str}_to_{end_dt_str}_cloudless_mosaic.npy\"\n",
    "cloudless_mosaic_path = abs_output_dir / city_name / \"sat_files\" / cloudless_mosaic_filename\n",
    "# --- Verification ---\n",
    "print(f\"City: {city_name}\")\n",
    "print(f\"Sentinel-2 Time Window: {sentinel_time_window}\")\n",
    "print(f\"Sentinel-2 Cloud Cover Threshold: {mosaic_cloud_cover}%\")\n",
    "print(f\"LST Time Window: {lst_time_window}\")\n",
    "print(f\"Bounds derived from {uhi_csv.name}: {bounds}\")\n",
    "print(f\"Target mosaic output path: {cloudless_mosaic_path}\")\n",
    "print(f\"Include LST: {include_lst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9627cf4-ed3d-4505-a95a-748c2ec5ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Generate Cloudless Mosaic --- \n",
    "print(f\"\\n--- Generating Cloudless Mosaic ({sentinel_time_window}) ---\")\n",
    "\n",
    "mosaic_output_path = create_and_save_cloudless_mosaic(\n",
    "    city_name=city_name,\n",
    "    bounds=bounds,\n",
    "    output_dir=abs_output_dir,\n",
    "    time_window=sentinel_time_window, # Use the explicit time window\n",
    "    selected_bands=mosaic_bands,\n",
    "    resolution_m=mosaic_resolution_m,\n",
    "    cloud_cover=mosaic_cloud_cover # Use the updated cloud cover\n",
    ")\n",
    "\n",
    "if mosaic_output_path:\n",
    "    print(f\"Cloudless mosaic saved/found at: {mosaic_output_path}\")\n",
    "else:\n",
    "    # Stop if mosaic fails, as it's required\n",
    "    raise RuntimeError(\"Failed to generate cloudless mosaic.\")\n",
    "\n",
    "# --- 2. Download Single LST Median (if enabled) ---\n",
    "print(f\"\\n--- Downloading Single LST Median (Include: {include_lst}, Window: {lst_time_window}) ---\")\n",
    "\n",
    "single_lst_median_file_path = None # Initialize path variable\n",
    "if include_lst:\n",
    "    # No need to check UHI CSV, we provide the time window directly\n",
    "    \n",
    "    # Download the single LST median using the explicit time window\n",
    "    single_lst_median_file_path = download_single_lst_median(\n",
    "        city_name=city_name,\n",
    "        bounds=bounds,\n",
    "        output_dir=abs_output_dir,\n",
    "        time_window=lst_time_window, # Provide explicit window\n",
    "        # uhi_csv_path and averaging_window are omitted/None\n",
    "        resolution_m=lst_resolution_m\n",
    "        # lst_cloud_cover is handled internally by load_lst_tensor_from_bbox_median\n",
    "    )\n",
    "\n",
    "    if single_lst_median_file_path:\n",
    "        print(f\"Single LST median saved/found at: {single_lst_median_file_path}\")\n",
    "    else:\n",
    "        print(\"Failed to generate single LST median.\")\n",
    "else:\n",
    "    print(\"Skipping LST median download as include_lst is False.\")\n",
    "\n",
    "# --- Verification ---\n",
    "sat_files_check_dir = Path(abs_output_dir) / city_name / \"sat_files\"\n",
    "print(f\"\\nVerifying output files:\")\n",
    "print(f\"  Mosaic path ({cloudless_mosaic_path.name}) exists: {cloudless_mosaic_path.exists()}\")\n",
    "if include_lst:\n",
    "    # Construct expected LST filename based on the explicit window\n",
    "    lst_start_str = lst_time_window.split('/')[0].replace('-','')\n",
    "    lst_end_str = lst_time_window.split('/')[1].replace('-','')\n",
    "    expected_lst_filename = f\"lst_{city_name}_median_{lst_start_str}_to_{lst_end_str}.npy\"\n",
    "    expected_lst_path = sat_files_check_dir / expected_lst_filename\n",
    "    print(f\"  Single LST median path ({expected_lst_filename}) exists: {expected_lst_path.exists()}\")\n",
    "    # Update the variable used by later cells if generation was successful\n",
    "    if single_lst_median_file_path and not single_lst_median_file_path.exists():\n",
    "         # This case shouldn't happen if the function worked, but good sanity check\n",
    "         print(f\"Warning: LST download function returned a path but it doesn't exist: {single_lst_median_file_path}\")\n",
    "         single_lst_median_file_path = None # Ensure later cells know it failed\n",
    "    elif not single_lst_median_file_path and expected_lst_path.exists():\n",
    "         # File existed previously, update path variable for later cells\n",
    "         single_lst_median_file_path = expected_lst_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244ca17",
   "metadata": {},
   "source": [
    "### 3. Download + Build DEM (DTM) / DSM for NYC from planetary computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71ee11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CONFIG\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# DEM/DSM specific settings\n",
    "# Fetching BOTH DEM and DSM from Planetary Computer\n",
    "\n",
    "# --- URLs and Paths ---\n",
    "CRS_WGS84 = \"EPSG:4326\"\n",
    "\n",
    "# Ensure the 'sat_files' directory exists\n",
    "sat_files_dir = abs_output_dir / city_name / \"sat_files\"\n",
    "sat_files_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Target Resolution --- # \n",
    "TARGET_ELEV_RESOLUTION_M = 10 # Target resolution in meters (downloading source 1m files make dataloading to the model extremely slow)\n",
    "# Approximate 10m in degrees at NYC latitude (approx 40.7 N)\n",
    "# Latitude: 1 deg ~ 111 km => 10m ~ 0.00009 deg\n",
    "# Longitude: 1 deg ~ 85 km => 10m ~ 0.000118 deg\n",
    "# Using the latitude approximation for stackstac resolution parameter\n",
    "TARGET_ELEV_RESOLUTION_DEG = 0.00009 \n",
    "\n",
    "# --- Define final expected TIF paths --- #\n",
    "# UPDATED Filenames to reflect 10m resolution\n",
    "final_dem_path_tif = sat_files_dir / f\"nyc_dem_{TARGET_ELEV_RESOLUTION_M}m_pc.tif\" \n",
    "final_dsm_path_tif = sat_files_dir / f\"nyc_dsm_{TARGET_ELEV_RESOLUTION_M}m_pc.tif\"\n",
    "\n",
    "# --- Define nodata value --- #\n",
    "ELEV_NODATA_VALUE = -9999.0 # Use a float value for both\n",
    "\n",
    "# --- Download DEM from Planetary Computer --- #\n",
    "print(f\"\\n--- Downloading DEM from Planetary Computer at approx {TARGET_ELEV_RESOLUTION_M}m resolution ---\")\n",
    "dem_downloaded_pc = False\n",
    "if final_dem_path_tif.exists():\n",
    "    logging.info(f\"DEM file {final_dem_path_tif.name} already exists. Skipping download.\")\n",
    "    dem_downloaded_pc = True\n",
    "else:\n",
    "    try:\n",
    "        # Ensure necessary libraries are imported (should be in cell 2)\n",
    "        import pystac_client\n",
    "        import planetary_computer\n",
    "        import stackstac\n",
    "        import rioxarray\n",
    "        import numpy as np\n",
    "\n",
    "        # Define bounding box and CRS for STAC query\n",
    "        bbox = bounds # Use the same bounds calculated earlier\n",
    "        logging.info(f\"Using bounding box for DEM query: {bbox}\")\n",
    "\n",
    "        # Search the 3dep-lidar-DTM collection (DEM)\n",
    "        catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=planetary_computer.sign_inplace)\n",
    "        search_dem = catalog.search(\n",
    "            collections=[\"3dep-lidar-dtm\"], # Use DTM collection\n",
    "            bbox=bbox,\n",
    "        )\n",
    "        items_dem = search_dem.item_collection()\n",
    "        logging.info(f\"Found {len(items_dem)} 3DEP DTM (DEM) items for the bounding box.\")\n",
    "\n",
    "        if not items_dem:\n",
    "            logging.warning(\"No 3DEP DTM (DEM) items found for the specified area. Cannot download DEM.\")\n",
    "        else:\n",
    "            # Load items, mean aggregate time, select the single band, then squeeze\n",
    "            logging.info(f\"Requesting DEM data from stackstac at resolution: {TARGET_ELEV_RESOLUTION_DEG} degrees\")\n",
    "            dem_data = stackstac.stack(\n",
    "                items_dem,\n",
    "                assets=[\"data\"],\n",
    "                epsg=4326,\n",
    "                resolution=TARGET_ELEV_RESOLUTION_DEG, # Use target 10m resolution in degrees\n",
    "                dtype=np.float32, # Save directly as float32\n",
    "                fill_value=ELEV_NODATA_VALUE,\n",
    "                rescale=False,\n",
    "                bounds_latlon=bbox\n",
    "            ).mean(\"time\", skipna=True) # Aggregate time first\n",
    "\n",
    "            # Explicitly select the single 'data' band if 'band' dimension exists\n",
    "            if \"band\" in dem_data.dims:\n",
    "                dem_data = dem_data.isel(band=0)\n",
    "\n",
    "            # Squeeze any remaining singleton dimensions\n",
    "            dem_data = dem_data.squeeze()\n",
    "\n",
    "            logging.info(f\"Created DEM xarray with shape: {dem_data.shape} and dtype: {dem_data.dtype}\")\n",
    "\n",
    "            # Assign CRS if missing\n",
    "            if dem_data.rio.crs is None:\n",
    "                 logging.warning(\"Assigning CRS EPSG:4326 to DEM data as it was missing after stackstac.\")\n",
    "                 dem_data = dem_data.rio.write_crs(CRS_WGS84)\n",
    "\n",
    "            # Set nodata value explicitly for writing\n",
    "            dem_data.rio.write_nodata(ELEV_NODATA_VALUE, inplace=True)\n",
    "\n",
    "            # Save the DataArray to a GeoTIFF (Filename now reflects 10m)\n",
    "            logging.info(f\"Saving DEM to {final_dem_path_tif}...\")\n",
    "            dem_data.rio.to_raster(final_dem_path_tif, driver=\"COG\") \n",
    "            logging.info(\"Successfully downloaded and saved DEM from Planetary Computer.\")\n",
    "            dem_downloaded_pc = True\n",
    "            del dem_data # Clean up memory\n",
    "\n",
    "    except ImportError as e:\n",
    "        logging.error(f\"Missing libraries for Planetary Computer access ({e}). Please install: pystac-client planetary-computer stackstac rioxarray numpy\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during Planetary Computer DEM download: {e}\", exc_info=True)\n",
    "\n",
    "# --- Download DSM from Planetary Computer --- #\n",
    "print(f\"\\n--- Downloading DSM from Planetary Computer at approx {TARGET_ELEV_RESOLUTION_M}m resolution ---\")\n",
    "dsm_downloaded_pc = False\n",
    "if final_dsm_path_tif.exists():\n",
    "    logging.info(f\"DSM file {final_dsm_path_tif.name} already exists. Skipping download.\")\n",
    "    dsm_downloaded_pc = True\n",
    "else:\n",
    "    try:\n",
    "        # Libraries should be imported already\n",
    "        import pystac_client\n",
    "        import planetary_computer\n",
    "        import stackstac\n",
    "        import rioxarray\n",
    "        import numpy as np\n",
    "\n",
    "        bbox = bounds # Use the same bounds\n",
    "        logging.info(f\"Using bounding box for DSM query: {bbox}\")\n",
    "\n",
    "        # Search the 3dep-lidar-dsm collection\n",
    "        catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=planetary_computer.sign_inplace)\n",
    "        search_dsm = catalog.search(\n",
    "            collections=[\"3dep-lidar-dsm\"],\n",
    "            bbox=bbox,\n",
    "        )\n",
    "        items_dsm = search_dsm.item_collection()\n",
    "        logging.info(f\"Found {len(items_dsm)} 3DEP DSM items for the bounding box.\")\n",
    "\n",
    "        if not items_dsm:\n",
    "            logging.warning(\"No 3DEP DSM items found for the specified area. Cannot download DSM.\")\n",
    "        else:\n",
    "            # Load items, mean aggregate time, select the single band, then squeeze\n",
    "            logging.info(f\"Requesting DSM data from stackstac at resolution: {TARGET_ELEV_RESOLUTION_DEG} degrees\")\n",
    "            dsm_data = stackstac.stack(\n",
    "                items_dsm,\n",
    "                assets=[\"data\"],\n",
    "                epsg=4326,\n",
    "                resolution=TARGET_ELEV_RESOLUTION_DEG, # Use target 10m resolution in degrees\n",
    "                dtype=np.float32, # Save directly as float32\n",
    "                fill_value=ELEV_NODATA_VALUE,\n",
    "                rescale=False,\n",
    "                bounds_latlon=bbox\n",
    "            ).mean(\"time\", skipna=True) # Aggregate time first\n",
    "\n",
    "            # Explicitly select the single 'data' band if 'band' dimension exists\n",
    "            if \"band\" in dsm_data.dims:\n",
    "                dsm_data = dsm_data.isel(band=0)\n",
    "\n",
    "            # Squeeze any remaining singleton dimensions\n",
    "            dsm_data = dsm_data.squeeze()\n",
    "\n",
    "            logging.info(f\"Created DSM xarray with shape: {dsm_data.shape} and dtype: {dsm_data.dtype}\")\n",
    "\n",
    "            # Assign CRS if missing\n",
    "            if dsm_data.rio.crs is None:\n",
    "                 logging.warning(\"Assigning CRS EPSG:4326 to DSM data as it was missing after stackstac.\")\n",
    "                 dsm_data = dsm_data.rio.write_crs(CRS_WGS84)\n",
    "\n",
    "            # Set nodata value explicitly for writing\n",
    "            dsm_data.rio.write_nodata(ELEV_NODATA_VALUE, inplace=True)\n",
    "\n",
    "            # Save the DataArray to a GeoTIFF (Filename now reflects 10m)\n",
    "            logging.info(f\"Saving DSM to {final_dsm_path_tif}...\")\n",
    "            dsm_data.rio.to_raster(final_dsm_path_tif, driver=\"COG\") \n",
    "            logging.info(\"Successfully downloaded and saved DSM from Planetary Computer.\")\n",
    "            dsm_downloaded_pc = True\n",
    "            del dsm_data # Clean up memory\n",
    "\n",
    "    except ImportError as e:\n",
    "        logging.error(f\"Missing libraries for Planetary Computer access ({e}). Please install: pystac-client planetary-computer stackstac rioxarray numpy\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during Planetary Computer DSM download: {e}\", exc_info=True)\n",
    "\n",
    "# --- Update Relative Paths for Config ---\n",
    "dem_path_relative = Path(\"data\") / city_name / \"sat_files\" / final_dem_path_tif.name\n",
    "dsm_path_relative = Path(\"data\") / city_name / \"sat_files\" / final_dsm_path_tif.name\n",
    "print(f\"\\nRelative paths for config (relative to project root '{project_root}'):\")\n",
    "print(f\"  DEM: {dem_path_relative}\")\n",
    "print(f\"  DSM: {dsm_path_relative}\")\n",
    "\n",
    "# --- Final Check ---\n",
    "print(\"\\n--- Final Status ---\")\n",
    "if final_dem_path_tif.exists():\n",
    "    print(f\"DEM file exists: {final_dem_path_tif}\")\n",
    "else:\n",
    "    print(\"DEM file NOT found.\")\n",
    "if final_dsm_path_tif.exists():\n",
    "    print(f\"DSM file exists: {final_dsm_path_tif}\")\n",
    "else:\n",
    "    print(\"DSM file NOT found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b88a1-a5fc-4261-91ec-979826ab3d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a7ceb-34ff-4621-be9d-1d775201a63c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
