{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64d05ec",
   "metadata": {},
   "source": [
    "# UHI Data Download and Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fad66",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94725a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import zipfile # For more robust unzipping\n",
    "import time\n",
    "\n",
    "# Imports for tile index processing\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Add the project root to the Python path to allow importing from src\n",
    "project_root = Path(os.getcwd()).parent  # Assumes notebook is in 'notebooks' subdir\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d213cf9-4623-420a-af80-3d7658873ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounds from UHI data: /Users/arnav/MLC-Project/data/NYC/uhi.csv\n",
      "Representative UHI date (from first row): 2021-07-24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuration for Data Download ---\n",
    "\n",
    "# Configure parameters for the target city (e.g., NYC)\n",
    "city_name = \"NYC\"\n",
    "\n",
    "# Time window matching original notebooks (adjust if needed)\n",
    "sentinel_time_window = \"2021-06-01/2021-09-01\"\n",
    "lst_time_window = \"2021-06-01/2021-09-01\"\n",
    "\n",
    "# Input files and general settings\n",
    "data_dir = Path(\"data\")\n",
    "abs_output_dir = project_root / data_dir\n",
    "uhi_csv = data_dir / city_name / \"uhi.csv\" # Path to UHI data\n",
    "abs_uhi_csv = project_root / uhi_csv\n",
    "# bbox_csv is no longer needed for bounds calculation\n",
    "\n",
    "if not abs_uhi_csv.exists():\n",
    "    raise FileNotFoundError(f\"UHI data CSV not found at {abs_uhi_csv}. Cannot derive bounds.\")\n",
    "print(f\"Loading bounds from UHI data: {abs_uhi_csv}\")\n",
    "uhi_df = pd.read_csv(abs_uhi_csv)\n",
    "# Check if required columns exist\n",
    "required_cols = ['Longitude', 'Latitude']\n",
    "if not all(col in uhi_df.columns for col in required_cols):\n",
    "     raise ValueError(f\"UHI CSV must contain columns: {required_cols}\")\n",
    "\n",
    "# Load bounds\n",
    "bounds = [\n",
    "    uhi_df['Longitude'].min(),\n",
    "    uhi_df['Latitude'].min(),\n",
    "    uhi_df['Longitude'].max(),\n",
    "    uhi_df['Latitude'].max()\n",
    "]\n",
    "\n",
    "# Load observation da\n",
    "first_datetime_obj = pd.to_datetime(uhi_df['datetime'].iloc[0], format='%d-%m-%Y %H:%M')\n",
    "# Format the date object into 'YYYY-MM-DD' string format\n",
    "uhi_date_str = first_datetime_obj.strftime('%Y-%m-%d')\n",
    "print(f\"Representative UHI date (from first row): {uhi_date_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af99245",
   "metadata": {},
   "source": [
    "## 2. Download Satellite Data for Cities\n",
    "\n",
    "Now we'll download satellite imagery data (Sentinel-2 median composites, Landsat LST medians) for specific cities and time periods derived from the UHI data timestamps. Data is saved locally for use by the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be014273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounds from UHI data: /home/jupyter/UHI/MLC-Project/data/NYC/uhi.csv\n",
      "City: NYC\n",
      "Sentinel-2 Time Window: 2021-06-01/2021-09-01\n",
      "Sentinel-2 Cloud Cover Threshold: 30%\n",
      "LST Time Window: 2021-06-01/2021-09-01\n",
      "Bounds derived from uhi.csv: [np.float64(-73.99445667), np.float64(40.75879167), np.float64(-73.87945833), np.float64(40.85949667)]\n",
      "Target mosaic output path: /home/jupyter/UHI/MLC-Project/data/NYC/sat_files/sentinel_NYC_20210601_to_20210901_cloudless_mosaic.npy\n",
      "Include LST: False\n"
     ]
    }
   ],
   "source": [
    "# Cell from notebooks/download_data.ipynb (modified)\n",
    "\n",
    "# Import functions\n",
    "from src.ingest.get_median import create_and_save_cloudless_mosaic\n",
    "# Import the modified LST download function\n",
    "from src.ingest.create_sat_tensor_files import download_single_lst_median\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Parameters for Cloudless Mosaic (matching Sentinel2_GeoTIFF.ipynb)\n",
    "mosaic_bands = [\"B02\", \"B03\", \"B04\", \"B08\"] # RGB+NIR for Clay compatibility\n",
    "mosaic_resolution_m = 10\n",
    "mosaic_cloud_cover = 30\n",
    "\n",
    "# Parameters for LST Median (matching Landsat_LST.ipynb)\n",
    "include_lst = False         # Whether to download LST\n",
    "lst_resolution_m = 30      # Native resolution for Landsat LST\n",
    "\n",
    "# Generate output path for the mosaic based on the new time window\n",
    "start_dt_str = sentinel_time_window.split('/')[0].replace('-','')\n",
    "end_dt_str = sentinel_time_window.split('/')[1].replace('-','')\n",
    "band_str = \"_\".join(mosaic_bands)\n",
    "cloudless_mosaic_filename = f\"sentinel_{city_name}_{start_dt_str}_to_{end_dt_str}_cloudless_mosaic.npy\"\n",
    "cloudless_mosaic_path = abs_output_dir / city_name / \"sat_files\" / cloudless_mosaic_filename\n",
    "# --- Verification ---\n",
    "print(f\"City: {city_name}\")\n",
    "print(f\"Sentinel-2 Time Window: {sentinel_time_window}\")\n",
    "print(f\"Sentinel-2 Cloud Cover Threshold: {mosaic_cloud_cover}%\")\n",
    "print(f\"LST Time Window: {lst_time_window}\")\n",
    "print(f\"Bounds derived from {uhi_csv.name}: {bounds}\")\n",
    "print(f\"Target mosaic output path: {cloudless_mosaic_path}\")\n",
    "print(f\"Include LST: {include_lst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244ca17",
   "metadata": {},
   "source": [
    "### 3. Download + Build DEM / DSM for NYC (AOI‑bounded, 1 ft grid)\n",
    "\n",
    "1. **Tile‑index fetch**  \n",
    "   * Pull both tile‑index shapefiles (DEM & LAS) from the NYS topo‑bathymetric 2017 FTP mirror.  \n",
    "   * They live in `/BE_DEM/…zip` and `/LAS/…zip`.  \n",
    "   * They’re unzipped to a temp folder, read by GeoPandas, then deleted.\n",
    "\n",
    "2. **Intersect AOI**  \n",
    "   * Your AOI bounds (given in decimal lat/long) are re‑projected to EPSG 2263.  \n",
    "   * We select only the DEM `.tif` tiles and LAS `.laz` tiles whose polygons hit that AOI.\n",
    "\n",
    "3. **Download source tiles**  \n",
    "   * DEM tiles (`be_NYC_###.tif`) stream straight from FTP to `dem_tiles/`.  \n",
    "   * LAS tiles (`hh_NYC_###.laz`) stream to `las_tiles/`.  \n",
    "   * Progress bars show raw byte count; no FTP `SIZE` calls (the server blocks those).\n",
    "\n",
    "4. **Build rasters**  \n",
    "   * **DEM** – `gdal_merge.py` mosaics the few BE tiles → `dem_merged_epsg2263.tif`.  \n",
    "   * **DSM** – PDAL crops the LAS hits, bins highest return (`output_type=max`), writes `dsm_epsg2263.tif` at 0.3048 m (1 ft) resolution.  \n",
    "   * Both rasters are then re‑projected with `gdalwarp` to EPSG 4326:  \n",
    "     `dem_epsg4326.tif`, `dsm_epsg4326.tif`.\n",
    "\n",
    "5. **Clean‑up**  \n",
    "   * All temp folders (`indices/`, `dem_tiles/`, `las_tiles/`) and intermediate rasters in EPSG 2263 are removed once the 4326 GeoTIFFs are verified non‑empty.  \n",
    "   * Leftover artefacts = **zero**. Only the two final products remain.\n",
    "\n",
    "**Data Source**\n",
    "\n",
    "* Source LiDAR survey: *NYC Topobathymetric LiDAR 2017* FTP server.\n",
    "* DEM tiles: bare‑earth (`be_…`) rasters published by NYS GIS Clearinghouse.  \n",
    "* DSM: freshly generated from the raw point cloud because no public HH DSM tiles exist, although the\n",
    "  state did publish them in 2017, they seem to have been deleted since.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "| File | CRS / Units | Resolution | Description |\n",
    "|------|-------------|------------|-------------|\n",
    "| `dem_epsg4326.tif` | EPSG 4326, metres in Z | ≈0.00000274° (~0.3048 m) | Bare‑earth ground elevation |\n",
    "| `dsm_epsg4326.tif` | EPSG 4326, metres in Z | same grid | Surface elevation (roofs, canopy) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d71ee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Downloading DEM/DSM for NYC ---\n",
      "Querying DEM API: https://elevation.its.ny.gov/arcgis/rest/services/Dem_Indexes/FeatureServer/0/query\n",
      "Found DEM download URL via API: https://gisdata.ny.gov/elevation/DEM/NYC_TopoBathymetric2017/be_NYC_001.tif\n",
      "Downloading nyc_dem_1ft_2017.zip from https://gisdata.ny.gov/elevation/DEM/NYC_TopoBathymetric2017/be_NYC_001.tif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nyc_dem_1ft_2017.zip:  27%|██▋       | 21.0M/77.8M [00:06<00:16, 3.57MiB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m dem_unzipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dem_download_url:\n\u001b[0;32m--> 132\u001b[0m     dem_downloaded \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdem_download_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdem_output_path_zip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dem_downloaded:\n\u001b[1;32m    134\u001b[0m         dem_unzipped \u001b[38;5;241m=\u001b[39m unzip_file(dem_output_path_zip, sat_files_dir)\n",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(url, output_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m block_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8192\u001b[39m \u001b[38;5;66;03m# Increased block size\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, tqdm(\n\u001b[1;32m     37\u001b[0m     desc\u001b[38;5;241m=\u001b[39moutput_path\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     38\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     42\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m bar:\n\u001b[0;32m---> 43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CONFIG\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "FTP_HOST       = \"ftp.gis.ny.gov\"\n",
    "FTP_ROOT       = \"/elevation/LIDAR/NYC_TopoBathymetric2017\"\n",
    "\n",
    "DEM_FTP_DIR    = f\"{FTP_ROOT}/BE_DEM\"     # be_NYC_###.tif + index zip\n",
    "LAS_FTP_DIR    = f\"{FTP_ROOT}/LAS\"        # hh_NYC_###.laz + index zip\n",
    "DEM_INDEX_FTP  = f\"{DEM_FTP_DIR}/tileindex_NYC_topobathy_BE_DEM_2017.zip\"\n",
    "LAS_INDEX_FTP  = f\"{LAS_FTP_DIR}/tileindex_2017_las.zip\"\n",
    "\n",
    "CRS_WGS84      = \"EPSG:4326\"\n",
    "CRS_NAD83_NY   = \"EPSG:2263\"\n",
    "\n",
    "root_out       = abs_output_dir / city_name / \"elevation\"\n",
    "index_dir      = root_out / \"indices\"\n",
    "dem_dir        = root_out / \"dem_tiles\"\n",
    "las_dir        = root_out / \"las_tiles\"\n",
    "root_out.mkdir(parents=True, exist_ok=True)\n",
    "for d in (index_dir, dem_dir, las_dir):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dem_index_zip  = index_dir / \"dem_index.zip\"\n",
    "las_index_zip  = index_dir / \"las_index.zip\"\n",
    "merged_dem2263 = root_out / \"dem_merged_epsg2263.tif\"\n",
    "dsm2263        = root_out / \"dsm_epsg2263.tif\"\n",
    "dem4326        = root_out / \"dem_epsg4326.tif\"\n",
    "dsm4326        = root_out / \"dsm_epsg4326.tif\"\n",
    "pdal_json      = root_out / \"dsm_pipeline.json\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# FTP helper (no SIZE)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def ftp_fetch(remote: str, local: Path, blk: int = 1 << 20) -> bool:\n",
    "    if local.exists():\n",
    "        return True\n",
    "    try:\n",
    "        with ftplib.FTP(FTP_HOST) as ftp:\n",
    "            ftp.login(); ftp.voidcmd(\"TYPE I\")\n",
    "            with open(local, \"wb\") as f, tqdm(desc=local.name, unit=\"iB\", unit_scale=True) as bar:\n",
    "                ftp.retrbinary(f\"RETR {remote}\",\n",
    "                               lambda ch: (f.write(ch), bar.update(len(ch)))[-1],\n",
    "                               blocksize=blk)\n",
    "        if local.stat().st_size == 0:\n",
    "            local.unlink(missing_ok=True)\n",
    "            raise RuntimeError(\"zero‑byte file\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"FTP error {remote}: {e}\")\n",
    "        local.unlink(missing_ok=True)\n",
    "        return False\n",
    "\n",
    "def unzip(zip_path: Path, out_dir: Path) -> Path:\n",
    "    with zipfile.ZipFile(zip_path) as z: z.extractall(out_dir)\n",
    "    return next(out_dir.glob(\"*.shp\"))\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Download and parse DEM tile‑index\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "ftp_fetch(DEM_INDEX_FTP, dem_index_zip)\n",
    "dem_index_shp = unzip(dem_index_zip, index_dir / \"dem_index\")\n",
    "dem_index_gdf = gpd.read_file(dem_index_shp)\n",
    "dem_index_gdf.crs = dem_index_gdf.crs or CRS_NAD83_NY\n",
    "\n",
    "# AOI in index CRS\n",
    "aoi = box(*bounds)\n",
    "aoi_native = gpd.GeoSeries([aoi], crs=CRS_WGS84).to_crs(dem_index_gdf.crs).iloc[0]\n",
    "\n",
    "dem_hits = dem_index_gdf[dem_index_gdf.geometry.intersects(aoi_native)]\n",
    "for loc in dem_hits[\"location\"]:\n",
    "    fname = Path(loc).name\n",
    "    ftp_fetch(f\"{DEM_FTP_DIR}/{fname}\", dem_dir / fname)\n",
    "\n",
    "# merge DEM tiles\n",
    "if not merged_dem2263.exists():\n",
    "    srcs = [rasterio.open(p) for p in dem_dir.glob(\"*.tif\")]\n",
    "    out, trans = rio_merge(srcs)\n",
    "    meta = srcs[0].meta.copy(); meta.update(driver=\"GTiff\",\n",
    "                                            height=out.shape[1],\n",
    "                                            width=out.shape[2],\n",
    "                                            transform=trans,\n",
    "                                            nodata=-9999)\n",
    "    with rasterio.open(merged_dem2263, \"w\", **meta) as dst: dst.write(out)\n",
    "    for s in srcs: s.close()\n",
    "\n",
    "# reproject DEM to EPSG:4326\n",
    "if not dem4326.exists():\n",
    "    subprocess.run([\"gdalwarp\", \"-t_srs\", CRS_WGS84, \"-r\", \"bilinear\",\n",
    "                    \"-dstnodata\", \"-9999\", \"-overwrite\",\n",
    "                    merged_dem2263, dem4326], check=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Download LAS tile‑index and intersect AOI\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "ftp_fetch(LAS_INDEX_FTP, las_index_zip)\n",
    "las_index_shp = unzip(las_index_zip, index_dir / \"las_index\")\n",
    "las_index_gdf = gpd.read_file(las_index_shp)\n",
    "las_index_gdf.crs = las_index_gdf.crs or CRS_NAD83_NY\n",
    "\n",
    "las_hits = las_index_gdf[las_index_gdf.geometry.intersects(aoi_native)]\n",
    "for loc in las_hits[\"location\"]:\n",
    "    fname = Path(loc).name\n",
    "    ftp_fetch(f\"{LAS_FTP_DIR}/{fname}.laz\", las_dir / f\"{fname}.laz\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Build DSM via PDAL (highest return)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "aoi_bounds = aoi_native.bounds\n",
    "pdal_pipeline = [\n",
    "    str(las_dir / \"*.laz\"),\n",
    "    {\"type\": \"filters.crop\",\n",
    "     \"bounds\": f\"[{aoi_bounds[0]},{aoi_bounds[2]}],[{aoi_bounds[1]},{aoi_bounds[3]}]\"},\n",
    "    {\"type\": \"writers.gdal\",\n",
    "     \"filename\": str(dsm2263),\n",
    "     \"resolution\": 0.3048,\n",
    "     \"output_type\": \"max\",\n",
    "     \"data_type\": \"float32\",\n",
    "     \"nodata\": -9999,\n",
    "     \"gdaldriver\": \"GTiff\"}\n",
    "]\n",
    "with open(pdal_json, \"w\") as f: json.dump(pdal_pipeline, f, indent=2)\n",
    "subprocess.run([\"pdal\", \"pipeline\", str(pdal_json)], check=True)\n",
    "\n",
    "# reproject DSM to EPSG:4326\n",
    "if not dsm4326.exists():\n",
    "    subprocess.run([\"gdalwarp\", \"-t_srs\", CRS_WGS84, \"-r\", \"bilinear\",\n",
    "                    \"-dstnodata\", \"-9999\", \"-overwrite\",\n",
    "                    dsm2263, dsm4326], check=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Summary paths for downstream loader\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\nFinished.\\nDEM:\", dem4326, \"\\nDSM:\", dsm4326)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
