{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0bd36b",
   "metadata": {},
   "source": [
    "# UHI Data Download and Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3faad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d05ec",
   "metadata": {},
   "source": [
    "# UHI Data Download and Processing Pipeline\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "1. Download and process UHI GeoTIFF files from sources like Fort Lauderdale (FTL) and convert them to CSV format\n",
    "2. Download satellite imagery for specific cities and time periods and save them locally\n",
    "3. Use local satellite data files with the dataloader instead of direct API calls\n",
    "\n",
    "The pipeline is designed to work with different city datasets with the same structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fad66",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94725a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Add the project root to the Python path to allow importing from src\n",
    "project_root = Path(os.getcwd()).parent  # Assumes notebook is in 'notebooks' subdir\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af99245",
   "metadata": {},
   "source": [
    "## 2. Download Satellite Data for Cities\n",
    "\n",
    "Now we'll download satellite imagery data (Sentinel-2 median composites, Landsat LST medians) for specific cities and time periods derived from the UHI data timestamps. Data is saved locally for use by the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import satellite data downloading functions\n",
    "from src.ingest.create_sat_tensor_files import download_data_from_uhi_csv\n",
    "\n",
    "# --- Configuration for Data Download ---\n",
    "\n",
    "# Configure parameters for the target city (e.g., NYC)\n",
    "city_name = \"NYC\"\n",
    "\n",
    "# Input files for the city (relative to project root)\n",
    "uhi_csv = f\"data/{city_name}/uhi_data.csv\"\n",
    "lower_left = [40.75, -74.01]\n",
    "upper_right = [40.88, -73.86]\n",
    "\n",
    "# Parameters for median composites and downloads\n",
    "averaging_window = 14  # Days to look back for median composites\n",
    "output_dir = \"data\"      # Base directory to save all downloaded data (Sentinel, LST, GOES)\n",
    "\n",
    "# Sentinel-2 Configuration\n",
    "selected_bands = [\"B02\", \"B03\", \"B04\", \"B08\"]  # Bands to use\n",
    "resolution_m = 10  # Resolution in meters\n",
    "\n",
    "# Landsat LST Configuration\n",
    "include_lst = True  # Include Landsat LST median composites\n",
    "\n",
    "# --- Verification ---\n",
    "# Verify the essential input files exist\n",
    "print(f\"Checking if UHI CSV exists: {os.path.exists(project_root / uhi_csv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download satellite data if input files exist\n",
    "print(f\"Starting satellite data download for {city_name}...\")\n",
    "print(f\"Include Landsat LST: {include_lst}\")\n",
    "\n",
    "# Convert paths to absolute\n",
    "abs_uhi_csv = str(project_root / uhi_csv)\n",
    "abs_output_dir = str(project_root / output_dir)\n",
    "\n",
    "# --- Download Sentinel, Landsat LST, and GOES LST --- \n",
    "# The function now handles all downloads based on flags\n",
    "lookup_table = download_data_from_uhi_csv(\n",
    "    city_name=city_name,\n",
    "    uhi_csv=abs_uhi_csv,\n",
    "    lower_left=lower_left,\n",
    "    upper_right=upper_right,\n",
    "    averaging_window=averaging_window,\n",
    "    output_dir=abs_output_dir,\n",
    "    selected_bands=selected_bands,\n",
    "    resolution_m=resolution_m,\n",
    "    include_lst=include_lst,\n",
    ")\n",
    "\n",
    "print(f\"\\nSatellite data download process complete for {city_name}.\")\n",
    "\n",
    "# --- Verification of Downloaded Data Directories ---\n",
    "sat_files_check_dir = Path(abs_output_dir) / city_name / \"sat_files\"\n",
    "\n",
    "print(f\"\\nVerifying output directories:\")\n",
    "print(f\"  Sentinel/Landsat LST dir ({sat_files_check_dir}) exists: {sat_files_check_dir.exists()}\")\n",
    "\n",
    "# Show first few entries in the lookup table (for Sentinel/Landsat medians)\n",
    "if lookup_table:\n",
    "    print(\"\\nSample entries from timewindow lookup table (Sentinel/Landsat):\")\n",
    "    count = 0\n",
    "    for time_window, files in lookup_table.items():\n",
    "        if count < 3:  # Show only first 3 entries\n",
    "            print(f\"  Time window: {time_window}\")\n",
    "            print(f\"    Sentinel file: {files.get('sentinel')}\")\n",
    "            print(f\"    LST file: {files.get('lst')}\")\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f2dff",
   "metadata": {},
   "source": [
    "## 4. Using Local Satellite Data with the Dataloader\n",
    "\n",
    "Finally, we'll demonstrate how to use the modified dataloader that works with local satellite data files instead of making API calls directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c990db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the local data loader\n",
    "from src.ingest.dataloaders_local import CityDataSet\n",
    "\n",
    "# Define the parameters for NYC (as an example)\n",
    "bounds = [-74.01, 40.75, -73.86, 40.88]  # NYC bounding box [min_lon, min_lat, max_lon, max_lat]\n",
    "averaging_window = 30  # Days to look back\n",
    "selected_bands = [\"B02\", \"B03\", \"B04\", \"B08\"]  # Sentinel-2 bands\n",
    "resolution_m = 10  # Spatial resolution in meters\n",
    "include_lst = True  # Include Land Surface Temperature data\n",
    "\n",
    "# CSV file paths\n",
    "uhi_csv = \"data/NYC/uhi_data.csv\"\n",
    "bbox_csv = \"data/NYC/bbox.csv\"\n",
    "weather_csv = \"data/NYC/weather_grid.csv\"\n",
    "\n",
    "# Base directory for stored satellite data and city name\n",
    "data_dir = \"data\"\n",
    "city_name = \"NYC\"\n",
    "\n",
    "# Verify satellite data directory exists\n",
    "sat_files_dir = Path(project_root) / data_dir / city_name / \"sat_files\"\n",
    "lookup_path = sat_files_dir / \"timewindow_lookup.json\"\n",
    "\n",
    "print(f\"Checking if satellite data directory exists: {os.path.exists(sat_files_dir)}\")\n",
    "print(f\"Checking if timewindow lookup file exists: {os.path.exists(lookup_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset if satellite data directory exists\n",
    "if os.path.exists(sat_files_dir) and os.path.exists(lookup_path):\n",
    "    try:\n",
    "        # Convert paths to absolute\n",
    "        abs_uhi_csv = str(project_root / uhi_csv)\n",
    "        abs_bbox_csv = str(project_root / bbox_csv)\n",
    "        abs_weather_csv = str(project_root / weather_csv)\n",
    "        abs_data_dir = str(project_root / data_dir)\n",
    "        \n",
    "        # Create the dataset with local satellite data\n",
    "        dataset = CityDataSet(\n",
    "            bounds=bounds,\n",
    "            averaging_window=averaging_window,\n",
    "            selected_bands=selected_bands,\n",
    "            resolution_m=resolution_m,\n",
    "            include_lst=include_lst,\n",
    "            uhi_csv=abs_uhi_csv,\n",
    "            bbox_csv=abs_bbox_csv,\n",
    "            weather_csv=abs_weather_csv,\n",
    "            data_dir=abs_data_dir,\n",
    "            city_name=city_name\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully initialized dataset with {len(dataset)} samples\")\n",
    "        \n",
    "        # Show dimensions of the first satellite tensor\n",
    "        if len(dataset) > 0:\n",
    "            first_sample = dataset[0]\n",
    "            satellite_tensor, weather_tensor, meta_tensor = first_sample\n",
    "            \n",
    "            print(f\"\\nFirst satellite tensor shape: {satellite_tensor.shape}\")\n",
    "            print(f\"Weather tensor: {weather_tensor}\")\n",
    "            print(f\"Meta tensor: {meta_tensor}\")\n",
    "            \n",
    "            # Plot the first satellite image (RGB composite)\n",
    "            if satellite_tensor.shape[0] >= 3:\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                # Extract R, G, B bands (assuming B04, B03, B02 order in selected_bands)\n",
    "                rgb_idx = [selected_bands.index(b) for b in [\"B04\", \"B03\", \"B02\"] if b in selected_bands]\n",
    "                if len(rgb_idx) == 3:\n",
    "                    # Create RGB composite and normalize for display\n",
    "                    rgb = satellite_tensor[rgb_idx, :, :]\n",
    "                    rgb = np.transpose(rgb, (1, 2, 0))\n",
    "                    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n",
    "                    plt.imshow(rgb)\n",
    "                    plt.title(f\"RGB Composite for {city_name}\")\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"Cannot display RGB composite: required bands not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing dataset: {e}\")\n",
    "else:\n",
    "    print(\"Satellite data directory or lookup file not found. Please run the satellite data download step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d2960",
   "metadata": {},
   "source": [
    "## 5. Adding a New City to the Pipeline\n",
    "\n",
    "Here's how to add a new city to the data pipeline:\n",
    "\n",
    "1. Prepare the UHI data CSV (lat;long;uhi) and bounding box CSV\n",
    "2. Create a directory structure: `data/CITY_NAME/`\n",
    "3. Run the satellite data download process for the new city\n",
    "4. Use the local dataloader with the new city's satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for adding a new city (commented out - template for reference)\n",
    "\"\"\"\n",
    "# Step 1: Set up directory structure\n",
    "new_city = \"MIAMI\"\n",
    "os.makedirs(f\"data/{new_city}\", exist_ok=True)\n",
    "\n",
    "# Step 2: If you have UHI GeoTIFFs, convert them to CSV\n",
    "geotiff_dir = f\"data/UHI_Surfaces_{new_city}\"\n",
    "if os.path.exists(geotiff_dir):\n",
    "    process_uhi_directories(\n",
    "        input_dirs=[geotiff_dir],\n",
    "        output_dir=\"data\"\n",
    "    )\n",
    "\n",
    "# Step 3: Prepare parameters\n",
    "city_bounds = [-80.32, 25.70, -80.12, 25.90]  # Example for Miami [min_lon, min_lat, max_lon, max_lat]\n",
    "uhi_csv = f\"data/{new_city}/uhi_data.csv\"\n",
    "bbox_csv = f\"data/{new_city}/bbox.csv\"\n",
    "weather_csv = f\"data/{new_city}/weather_grid.csv\"\n",
    "\n",
    "# Step 4: Download satellite data\n",
    "download_data_from_uhi_csv(\n",
    "    city_name=new_city,\n",
    "    uhi_csv=uhi_csv,\n",
    "    bbox_csv=bbox_csv,\n",
    "    averaging_window=30,\n",
    "    output_dir=\"data\",\n",
    "    selected_bands=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "    resolution_m=10,\n",
    "    include_lst=True\n",
    ")\n",
    "\n",
    "# Step 5: Initialize the dataset with local data\n",
    "dataset = CityDataSet(\n",
    "    bounds=city_bounds,\n",
    "    averaging_window=30,\n",
    "    selected_bands=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "    resolution_m=10,\n",
    "    include_lst=True,\n",
    "    uhi_csv=uhi_csv,\n",
    "    bbox_csv=bbox_csv,\n",
    "    weather_csv=weather_csv,\n",
    "    data_dir=\"data\",\n",
    "    city_name=new_city\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cafb44",
   "metadata": {},
   "source": [
    "## 3a. Download Weather Grid Data for the City\n",
    "\n",
    "Next, we download daily weather data (max/min temperature, precipitation) for a grid covering the city's bounding box. This data is used by the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8748a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Function to fetch weather data from Open-Meteo\n",
    "def get_openmeteo_weather(lat, lon, start_date, end_date):\n",
    "    url = (\n",
    "        \"https://archive-api.open-meteo.com/v1/archive?\"\n",
    "        f\"latitude={lat}&longitude={lon}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        \"&daily=temperature_2m_max,temperature_2m_min,precipitation_sum\"\n",
    "        \"&timezone=America/New_York\" # Consider making timezone configurable if needed\n",
    "    )\n",
    "    try:\n",
    "        res = requests.get(url, timeout=30) # Added timeout\n",
    "        res.raise_for_status() # Raise HTTPError for bad responses (4XX, 5XX)\n",
    "        return res.json()[\"daily\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"API request failed for ({lat},{lon}): {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed processing weather for ({lat},{lon}): {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Weather Configuration ---\n",
    "# Use the city_name and bbox_csv defined in the previous cell (Cell 9)\n",
    "weather_city_name = city_name\n",
    "weather_bbox_csv = project_root / bbox_csv # Use the relative path defined earlier\n",
    "\n",
    "# Define grid interval and date range\n",
    "grid_interval = 0.01 # Degrees (~1km) - adjust if needed\n",
    "start_date = \"2021-06-01\" # Match the example script - adjust if needed\n",
    "end_date = \"2021-09-01\"   # Match the example script - adjust if needed\n",
    "\n",
    "# Output path for weather data\n",
    "weather_output_dir = project_root / \"data\" / weather_city_name\n",
    "weather_output_file = weather_output_dir / \"weather_grid.csv\"\n",
    "\n",
    "# --- Weather Data Download ---\n",
    "print(f\"\\nStarting weather data download for {weather_city_name}...\")\n",
    "print(f\"Using bbox file: {weather_bbox_csv}\")\n",
    "print(f\"Output file: {weather_output_file}\")\n",
    "\n",
    "if not os.path.exists(weather_bbox_csv):\n",
    "    print(f\"Error: Bounding box file not found at {weather_bbox_csv}. Skipping weather download.\")\n",
    "else:\n",
    "    # Read bounding box\n",
    "    bbox_df = pd.read_csv(weather_bbox_csv)\n",
    "    min_lat, max_lat = bbox_df['latitudes'].min(), bbox_df['latitudes'].max()\n",
    "    min_lon, max_lon = bbox_df['longitudes'].min(), bbox_df['longitudes'].max()\n",
    "\n",
    "    # Create grid points, ensuring ranges cover the max values\n",
    "    lats = np.arange(min_lat, max_lat + grid_interval, grid_interval)\n",
    "    lons = np.arange(min_lon, max_lon + grid_interval, grid_interval)\n",
    "    grid_points = [(round(lat, 4), round(lon, 4)) for lat in lats for lon in lons] # Rounded for precision\n",
    "    print(f\"Generated {len(grid_points)} grid points for weather data.\")\n",
    "\n",
    "    # Get weather data for each grid point\n",
    "    weather_records = []\n",
    "    successful_fetches = 0\n",
    "    for i, (lat, lon) in enumerate(grid_points):\n",
    "        if (i + 1) % 50 == 0: # Log progress every 50 points\n",
    "             print(f\"  Fetching weather for point {i+1}/{len(grid_points)} ({lat}, {lon})...\")\n",
    "             \n",
    "        daily_data = get_openmeteo_weather(lat, lon, start_date, end_date)\n",
    "        if daily_data and 'time' in daily_data: # Check if data was fetched successfully\n",
    "            successful_fetches += 1\n",
    "            for idx, date in enumerate(daily_data[\"time\"]):\n",
    "                weather_records.append({\n",
    "                    \"lat\": lat,\n",
    "                    \"lon\": lon,\n",
    "                    \"date\": date,\n",
    "                    \"temp_max\": daily_data[\"temperature_2m_max\"][idx],\n",
    "                    \"temp_min\": daily_data[\"temperature_2m_min\"][idx],\n",
    "                    \"precip\": daily_data[\"precipitation_sum\"][idx],\n",
    "                })\n",
    "        # Optional: Add a small delay between requests if needed\n",
    "        # import time\n",
    "        # time.sleep(0.1)\n",
    "\n",
    "    print(f\"Successfully fetched data for {successful_fetches} out of {len(grid_points)} grid points.\")\n",
    "\n",
    "    if not weather_records:\n",
    "        print(\"No weather data was successfully downloaded. CSV file not created.\")\n",
    "    else:\n",
    "        # Save the weather data to a CSV file\n",
    "        df_weather = pd.DataFrame(weather_records)\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(weather_output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Saving weather data with {len(df_weather)} records to {weather_output_file}...\")\n",
    "        df_weather.to_csv(weather_output_file, index=False, float_format='%.4f')\n",
    "        print(f\"Weather data saved successfully.\")\n",
    "\n",
    "print(\"\\nWeather data download process finished.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
