{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d496d31",
   "metadata": {},
   "source": [
    "# New Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a48f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d7a28",
   "metadata": {},
   "source": [
    "## 3. Download DEM/DSM Tiles via Index Shapefile\n",
    "\n",
    "Download required Digital Elevation Model (DEM) and Digital Surface Model (DSM) tiles using the official NYC index shapefiles. This method determines which specific tiles intersect our study area bounds (defined earlier from `uhi.csv`) and downloads only those tiles.\n",
    "\n",
    "- **Source:** NYC OpenData / NYS GIS Clearinghouse (`gisdata.ny.gov`)\n",
    "- **Data:** 2017 LiDAR DEM & DSM (Highest Hit)\n",
    "- **Format:** GeoTIFF tiles\n",
    "- **Method:** \n",
    "    1. Download index shapefile zip.\n",
    "    2. Extract shapefile.\n",
    "    3. Define study area polygon from `bounds` (WGS84).\n",
    "    4. Reproject study area polygon to the shapefile's CRS (EPSG:2263 - NAD83 / New York Long Island (ftUS)).\n",
    "    5. Iterate through shapefile features.\n",
    "    6. If a feature's geometry intersects the reprojected study area, download the corresponding tile using the `location` attribute.\n",
    "    7. Repeat for both DEM and DSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d86601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries if not already present\n",
    "!pip install fiona shapely pyproj requests tqdm --quiet\n",
    "\n",
    "import fiona\n",
    "import shapely.geometry\n",
    "import pyproj\n",
    "import shapely.ops\n",
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import logging \n",
    "\n",
    "# --- Configuration ---\n",
    "DSM_INDEX_URL = \"https://gisdata.ny.gov/elevation/DEM/NYC_TopoBathymetric2017_DSM/NYC_TopoBathymetric2017_DSM_Index.zip\"\n",
    "DSM_TILE_BASE_URL = \"https://gisdata.ny.gov/elevation/DEM/NYC_TopoBathymetric2017_DSM/\"\n",
    "# Assume DEM follows a similar pattern (verify if needed)\n",
    "DEM_INDEX_URL = \"https://gisdata.ny.gov/elevation/DEM/NYC_TopoBathymetric2017_DEM/NYC_TopoBathymetric2017_DEM_Index.zip\"\n",
    "DEM_TILE_BASE_URL = \"https://gisdata.ny.gov/elevation/DEM/NYC_TopoBathymetric2017_DEM/\"\n",
    "\n",
    "TEMP_DIR = Path(\"./temp_gis_download\")\n",
    "TILE_SAVE_DIR = Path(\"../data/elevation/tiles\") # Relative to notebook\n",
    "\n",
    "# CRS Information\n",
    "WGS84_CRS = \"EPSG:4326\"\n",
    "NYC_LI_CRS = \"EPSG:2263\" # NAD83 / New York Long Island (ftUS)\n",
    "\n",
    "# Logger setup (reuse existing if possible, else configure)\n",
    "try: \n",
    "    logger = logging.getLogger()\n",
    "    if not logger.handlers: raise Exception(\"No handlers\")\n",
    "except Exception:\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def download_file_simple(url, output_path):\n",
    "    \"\"\"Downloads a file with progress bar.\"\"\"\n",
    "    if output_path.exists():\n",
    "        logger.info(f\"File {output_path.name} already exists. Skipping download.\")\n",
    "        return True\n",
    "    try:\n",
    "        logger.info(f\"Downloading {output_path.name} from {url}...\")\n",
    "        response = requests.get(url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 8192\n",
    "\n",
    "        with open(output_path, 'wb') as f, tqdm(\n",
    "            desc=output_path.name,\n",
    "            total=total_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for data in response.iter_content(block_size):\n",
    "                size = f.write(data)\n",
    "                bar.update(size)\n",
    "        logger.info(f\"Successfully downloaded {output_path.name}\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error downloading {output_path.name}: {e}\")\n",
    "        if output_path.exists(): os.remove(output_path)\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during download of {output_path.name}: {e}\")\n",
    "        if output_path.exists(): os.remove(output_path)\n",
    "        return False\n",
    "\n",
    "def extract_zip(zip_path, extract_to):\n",
    "    \"\"\"Extracts a zip file.\"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            logger.info(f\"Extracting {zip_path.name} to {extract_to}...\")\n",
    "            zip_ref.extractall(extract_to)\n",
    "            logger.info(f\"Successfully extracted {zip_path.name}.\")\n",
    "            # Find the shapefile within the extracted contents\n",
    "            shp_files = list(Path(extract_to).rglob('*.shp'))\n",
    "            if not shp_files:\n",
    "                 logger.error(f\"No .shp file found in extracted contents of {zip_path.name}\")\n",
    "                 return None\n",
    "            # Assume the first .shp found is the correct one\n",
    "            logger.info(f\"Found shapefile: {shp_files[0]}\")\n",
    "            return shp_files[0]\n",
    "    except zipfile.BadZipFile:\n",
    "        logger.error(f\"Error: {zip_path.name} is not a valid zip file or is corrupted.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting {zip_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_tiles_for_bounds(index_shp_path, tile_base_url, bounds_wgs84, target_tile_dir, tile_prefix):\n",
    "    \"\"\"Finds and downloads tiles intersecting bounds.\"\"\"\n",
    "    \n",
    "    required_tile_urls = []\n",
    "    downloaded_count = 0\n",
    "    target_tile_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # 1. Define Study Area Polygon (WGS84)\n",
    "        min_lon, min_lat, max_lon, max_lat = bounds_wgs84\n",
    "        study_area_wgs84 = shapely.geometry.box(min_lon, min_lat, max_lon, max_lat)\n",
    "        \n",
    "        # 2. Define CRS and Transformation\n",
    "        transformer = pyproj.Transformer.from_crs(WGS84_CRS, NYC_LI_CRS, always_xy=True)\n",
    "        \n",
    "        # 3. Reproject Study Area to Index CRS (EPSG:2263)\n",
    "        projected_study_area = shapely.ops.transform(transformer.transform, study_area_wgs84)\n",
    "        logger.info(f\"Reprojected study area bounds (EPSG:{NYC_LI_CRS}): {projected_study_area.bounds}\")\n",
    "\n",
    "        # 4. Open Shapefile and Find Intersecting Tiles\n",
    "        with fiona.open(index_shp_path) as index_source:\n",
    "            logger.info(f\"Opened index shapefile: {index_shp_path}. CRS: {index_source.crs}\")\n",
    "            # Basic CRS check (should be EPSG:2263 or similar)\n",
    "            if str(NYC_LI_CRS) not in str(index_source.crs):\n",
    "                 logger.warning(f\"Index CRS ({index_source.crs}) may not match expected {NYC_LI_CRS}. Intersection check might be inaccurate.\")\n",
    "                 \n",
    "            intersecting_features = 0\n",
    "            for feature in index_source:\n",
    "                tile_geom = shapely.geometry.shape(feature['geometry'])\n",
    "                if projected_study_area.intersects(tile_geom):\n",
    "                    intersecting_features += 1\n",
    "                    tile_filename = feature['properties'].get('location') # Get filename (e.g., hh_995000_185000.tif)\n",
    "                    if tile_filename:\n",
    "                        tile_url = tile_base_url + tile_filename\n",
    "                        required_tile_urls.append(tile_url)\n",
    "                    else:\n",
    "                        logger.warning(f\"Feature intersects but has no 'location' property: {feature['properties']}\")\n",
    "            logger.info(f\"Found {len(required_tile_urls)} intersecting tiles out of {intersecting_features} intersecting features.\")\n",
    "\n",
    "        # 5. Download Required Tiles\n",
    "        for tile_url in required_tile_urls:\n",
    "            tile_filename = tile_url.split('/')[-1]\n",
    "            # Add prefix to distinguish DEM/DSM locally\n",
    "            local_filename = f\"{tile_prefix}_{tile_filename}\" \n",
    "            local_tile_path = target_tile_dir / local_filename\n",
    "            if download_file_simple(tile_url, local_tile_path):\n",
    "                 downloaded_count += 1\n",
    "                 \n",
    "    except fiona.errors.DriverError as e:\n",
    "        logger.error(f\"Fiona error opening index {index_shp_path}: {e}. Is the file valid and dependencies installed?\")\n",
    "    except ImportError as e:\n",
    "        logger.error(f\"Error: Missing libraries required for tile indexing ({e}). Please install fiona, shapely, pyproj.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during tile processing for {index_shp_path.name}: {e}\", exc_info=True)\n",
    "        \n",
    "    return downloaded_count\n",
    "\n",
    "# --- Main Execution ---\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "success = True\n",
    "\n",
    "# --- Process DSM ---\n",
    "print(\"\\n--- Processing DSM --- \")\n",
    "dsm_zip_path = TEMP_DIR / \"dsm_index.zip\"\n",
    "dsm_extract_dir = TEMP_DIR / \"dsm_index\"\n",
    "dsm_shp_path = None\n",
    "dsm_downloaded = 0\n",
    "\n",
    "if download_file_simple(DSM_INDEX_URL, dsm_zip_path):\n",
    "    dsm_shp_path = extract_zip(dsm_zip_path, dsm_extract_dir)\n",
    "    if dsm_shp_path:\n",
    "        dsm_downloaded = get_tiles_for_bounds(dsm_shp_path, DSM_TILE_BASE_URL, bounds, TILE_SAVE_DIR / \"dsm\", \"dsm\")\n",
    "        logger.info(f\"Downloaded {dsm_downloaded} DSM tiles.\")\n",
    "    else:\n",
    "        logger.error(\"Failed to extract or find DSM shapefile.\")\n",
    "        success = False\n",
    "else:\n",
    "    logger.error(\"Failed to download DSM index zip.\")\n",
    "    success = False\n",
    "\n",
    "# --- Process DEM ---\n",
    "print(\"\\n--- Processing DEM --- \")\n",
    "dem_zip_path = TEMP_DIR / \"dem_index.zip\"\n",
    "dem_extract_dir = TEMP_DIR / \"dem_index\"\n",
    "dem_shp_path = None\n",
    "dem_downloaded = 0\n",
    "\n",
    "if download_file_simple(DEM_INDEX_URL, dem_zip_path):\n",
    "    dem_shp_path = extract_zip(dem_zip_path, dem_extract_dir)\n",
    "    if dem_shp_path:\n",
    "        dem_downloaded = get_tiles_for_bounds(dem_shp_path, DEM_TILE_BASE_URL, bounds, TILE_SAVE_DIR / \"dem\", \"dem\")\n",
    "        logger.info(f\"Downloaded {dem_downloaded} DEM tiles.\")\n",
    "    else:\n",
    "        logger.error(\"Failed to extract or find DEM shapefile.\")\n",
    "        success = False # Mark as failed, but maybe DEM isn't strictly required?\n",
    "else:\n",
    "    # This might be expected if the assumed DEM url is wrong\n",
    "    logger.warning(f\"Failed to download DEM index zip from {DEM_INDEX_URL}. URL might be incorrect or data unavailable.\") \n",
    "    # Don't mark overall success as False just for DEM failure if DSM worked\n",
    "\n",
    "# --- Cleanup (Optional) ---\n",
    "# print(\"\\n--- Cleaning up temporary files ---\")\n",
    "# try:\n",
    "#     import shutil\n",
    "#     shutil.rmtree(TEMP_DIR)\n",
    "#     print(f\"Removed temporary directory: {TEMP_DIR}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error removing temporary directory {TEMP_DIR}: {e}\")\n",
    "\n",
    "print(\"\\n--- Download Process Summary ---\")\n",
    "print(f\"DSM Tiles Downloaded: {dsm_downloaded}\")\n",
    "print(f\"DEM Tiles Downloaded: {dem_downloaded}\")\n",
    "print(f\"Tiles saved to: {TILE_SAVE_DIR}\")\n",
    "if not success and dsm_downloaded == 0:\n",
    "    print(\"\\n*** Errors occurred, DSM download failed. Check logs above. ***\")\n",
    "elif dem_downloaded == 0:\n",
    "    print(\"\\n*** Note: DEM index download failed or found 0 DEM tiles. Check URL or logs. ***\")\n",
    "else:\n",
    "     print(\"\\nTile download process finished.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
