{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97feb2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from box import Box\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # Added for interpolation\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # Needed for loading bounds from csv\n",
    "from tqdm.notebook import tqdm # Use notebook tqdm\n",
    "import math \n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# --- WANDB --- #\n",
    "import wandb\n",
    "# ------------ #\n",
    "\n",
    "# --- Metrics --- \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# ------------ #\n",
    "\n",
    "# Add src directory to path to import modules\n",
    "project_root = Path(os.getcwd()).parent  # Assumes notebook is in 'notebooks' subdir\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.model import UHINetCNN\n",
    "from src.ingest.dataloader import CityDataSet\n",
    "\n",
    "from src.train.loss import masked_mae_loss, masked_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860c52a0-0d4b-4e3e-a2fc-363a45e9abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNCOMMENT ON FIRST RUN\n",
    "#!wget -q https://huggingface.co/made-with-clay/Clay/resolve/main/v1.5/clay-v1.5.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e727ff",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up paths and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca486df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded bounds from uhi.csv: [-73.99445667, 40.75879167, -73.87945833, 40.85949667]\n",
      "\n",
      "Configuration dictionary created:\n",
      "{\n",
      "  \"model_type\": \"UHINetCNN\",\n",
      "  \"project_root\": \"/home/jupyter/MLC-Project\",\n",
      "  \"city_name\": \"NYC\",\n",
      "  \"wandb_project_name\": \"MLC_UHI_Proj\",\n",
      "  \"wander_run_name_prefix\": \"NYC_UHINetCNN\",\n",
      "  \"resolution_m\": 10,\n",
      "  \"include_lst\": true,\n",
      "  \"uhi_csv\": \"data/NYC/uhi.csv\",\n",
      "  \"bronx_weather_csv\": \"/home/jupyter/MLC-Project/data/NYC/bronx_weather.csv\",\n",
      "  \"manhattan_weather_csv\": \"/home/jupyter/MLC-Project/data/NYC/manhattan_weather.csv\",\n",
      "  \"cloudless_mosaic_path\": \"/home/jupyter/MLC-Project/data/NYC/sat_files/sentinel_NYC_20210601_to_20210901_cloudless_mosaic.npy\",\n",
      "  \"single_lst_median_path\": \"/home/jupyter/MLC-Project/data/NYC/sat_files/lst_NYC_median_20210601_to_20210901.npy\",\n",
      "  \"bounds\": [\n",
      "    -73.99445667,\n",
      "    40.75879167,\n",
      "    -73.87945833,\n",
      "    40.85949667\n",
      "  ],\n",
      "  \"clay_model_size\": \"large\",\n",
      "  \"clay_bands\": [\n",
      "    \"blue\",\n",
      "    \"green\",\n",
      "    \"red\",\n",
      "    \"nir\"\n",
      "  ],\n",
      "  \"clay_platform\": \"sentinel-2-l2a\",\n",
      "  \"clay_gsd\": 10,\n",
      "  \"clay_checkpoint_path\": \"/home/jupyter/MLC-Project/notebooks/clay-v1.5.ckpt\",\n",
      "  \"clay_metadata_path\": \"/home/jupyter/MLC-Project/src/Clay/configs/metadata.yaml\",\n",
      "  \"weather_channels\": 6,\n",
      "  \"time_embed_dim\": 2,\n",
      "  \"lst_channels\": 1,\n",
      "  \"proj_ch\": 64,\n",
      "  \"cnn_hidden_dims\": [\n",
      "    32,\n",
      "    16,\n",
      "    8\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 3,\n",
      "  \"n_train_batches\": 8,\n",
      "  \"num_workers\": 4,\n",
      "  \"epochs\": 500,\n",
      "  \"lr\": 5e-05,\n",
      "  \"weight_decay\": 0.01,\n",
      "  \"loss_type\": \"mse\",\n",
      "  \"patience\": 50,\n",
      "  \"device\": \"cuda\",\n",
      "  \"cnn_dropout\": 0.3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# %% Configuration / Hyperparameters\n",
    "\n",
    "# --- Paths & Basic Info ---\n",
    "project_root_str = str(project_root) # Store as string for config\n",
    "data_dir_base = project_root / \"data\"\n",
    "city_name = \"NYC\"\n",
    "output_dir_base = project_root / \"training_runs\"\n",
    "\n",
    "# --- WANDB Config ---\n",
    "wandb_project_name = \"MLC_UHI_Proj\"\n",
    "wander_run_name_prefix = f\"{city_name}_UHINetCNN_HiResElev\" # Modified prefix\n",
    "\n",
    "# --- Data Loading Config ---\n",
<<<<<<< HEAD
    "resolution_m = 10 # Target resolution for *low-res* features (UHI, Weather, LST, Clay)\n",
=======
    "resolution_m = 10 # UHI/Weather/Mosaic grid resolution\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "include_lst = True\n",
    "\n",
    "# Input Data Paths (relative to project root for portability in config)\n",
    "relative_data_dir = Path(\"data\")\n",
    "relative_uhi_csv = relative_data_dir / city_name / \"uhi.csv\"\n",
    "relative_bronx_weather_csv = relative_data_dir / city_name / \"bronx_weather.csv\"\n",
    "relative_manhattan_weather_csv = relative_data_dir / city_name / \"manhattan_weather.csv\"\n",
    "relative_cloudless_mosaic_path = relative_data_dir / city_name / \"sat_files\" / f\"sentinel_{city_name}_20210601_to_20210901_cloudless_mosaic.npy\"\n",
    "relative_single_lst_median_path = relative_data_dir / city_name / \"sat_files\" / f\"lst_{city_name}_median_20210601_to_20210901.npy\"\n",
    "\n",
<<<<<<< HEAD
    "# --- HIGH-RES DEM/DSM Paths (Relative) --- #\n",
    "relative_dem_path = relative_data_dir / city_name / \"sat_files\" / \"nyc_dem_1ft_2017.tif\"\n",
    "relative_dsm_path = relative_data_dir / city_name / \"sat_files\" / \"nyc_dsm_1m_pc.tif\"\n",
    "high_res_nodata = np.nan # Nodata value used in the high-res files (NaN for PC DSM)\n",
    "# --- END HIGH-RES --- #\n",
=======
    "# --- UPDATED DEM/DSM Paths (Relative to project root, pointing to generated files) --- #\n",
    "relative_dem_path = relative_data_dir / city_name / \"sat_files\" / f\"{city_name}_dem_1ft_epsg4326.tif\"\n",
    "relative_dsm_path = relative_data_dir / city_name / \"sat_files\" / f\"{city_name}_dsm_1ft_epsg4326.tif\"\n",
    "# --- END UPDATED ---\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "\n",
    "# --- Model Config ---\n",
    "# Clay Backbone\n",
    "clay_model_size = \"large\"\n",
    "clay_bands = [\"blue\", \"green\", \"red\", \"nir\"]\n",
    "clay_platform = \"sentinel-2-l2a\"\n",
    "clay_gsd = 10\n",
    "freeze_backbone = True\n",
<<<<<<< HEAD
=======
    "\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "relative_clay_checkpoint_path = \"notebooks/clay-v1.5.ckpt\"\n",
    "relative_clay_metadata_path = Path(\"src\") / \"Clay\" / \"configs\" / \"metadata.yaml\"\n",
    "\n",
    "# UHINetCNN\n",
    "weather_channels = 6\n",
    "time_embed_dim = 2 # Not directly used by CNN\n",
    "lst_channels = 1 if include_lst else 0\n",
<<<<<<< HEAD
    "# --- High-Res Elevation Branch Config --- #\n",
    "include_dem_branch = True # <<< ENABLE DEM BRANCH\n",
    "include_dsm_branch = True # <<< ENABLE DSM BRANCH\n",
    "elevation_out_channels = 32 # <<< Output channels for each branch\n",
    "# --- END High-Res Branch --- #\n",
    "proj_ch = 64 # Channels after projecting Clay features\n",
    "head_type = 'unet' # Options: 'unet', 'simple_cnn'\n",
    "# Simple CNN args (ignored if head_type='unet')\n",
    "cnn_hidden_dims = [64, 32]\n",
    "cnn_kernel_size = 3\n",
    "cnn_dropout = 0.1\n",
    "# U-Net args (used if head_type='unet')\n",
=======
    "# DEM/DSM Channels & Inclusion Flags\n",
    "dem_channels = 1 # If DEM is included\n",
    "dsm_channels = 1 # If DSM is included\n",
    "include_dem = True # Flag to control DEM inclusion\n",
    "include_dsm = True # Flag to control DSM inclusion\n",
    "\n",
    "proj_ch = 64 # Used if head_type = 'simple_cnn'\n",
    "head_type = 'unet' # Options: 'unet', 'simple_cnn'\n",
    "# Simple CNN args\n",
    "cnn_hidden_dims = [64, 32]\n",
    "cnn_kernel_size = 3\n",
    "cnn_dropout = 0.1\n",
    "# U-Net args\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "unet_base_channels = 64\n",
    "unet_depth = 4\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "num_workers = 4\n",
    "epochs = 500\n",
    "lr = 5e-5\n",
    "weight_decay = 0.01\n",
    "loss_type = 'mse'\n",
    "patience = 50\n",
    "cpu = False\n",
    "n_train_batches = 8\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not cpu else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Sanity Checks and Absolute Paths ---\n",
    "def check_path(relative_path, description, should_exist=True):\n",
    "    if relative_path is None: return None # Allow None paths\n",
    "    abs_path = project_root / relative_path\n",
    "    if should_exist and not abs_path.exists():\n",
    "        raise FileNotFoundError(f\"{description} not found at expected location: {abs_path}. Ensure download_data.ipynb generated the file.\")\n",
    "    return abs_path\n",
    "\n",
    "absolute_uhi_csv = check_path(relative_uhi_csv, \"UHI CSV\")\n",
    "absolute_bronx_weather_csv = check_path(relative_bronx_weather_csv, \"Bronx Weather CSV\")\n",
    "absolute_manhattan_weather_csv = check_path(relative_manhattan_weather_csv, \"Manhattan Weather CSV\")\n",
    "absolute_cloudless_mosaic_path = check_path(relative_cloudless_mosaic_path, \"Cloudless Mosaic\")\n",
    "absolute_clay_checkpoint_path = check_path(relative_clay_checkpoint_path, \"Clay Checkpoint\")\n",
    "absolute_clay_metadata_path = check_path(relative_clay_metadata_path, \"Clay Metadata\")\n",
<<<<<<< HEAD
    "absolute_single_lst_median_path = check_path(relative_single_lst_median_path, \"Single LST Median\") if include_lst else None\n",
    "# --- Check High-Res DEM/DSM paths --- #\n",
    "absolute_dem_path = check_path(relative_dem_path, \"High-Res DEM TIF\") if include_dem_branch else None\n",
    "absolute_dsm_path = check_path(relative_dsm_path, \"High-Res DSM TIF\") if include_dsm_branch else None\n",
    "# --- END Check --- #\n",
=======
    "absolute_single_lst_median_path = None\n",
    "if include_lst:\n",
    "    absolute_single_lst_median_path = check_path(relative_single_lst_median_path, \"Single LST Median\")\n",
    "\n",
    "# --- Check *NEW* DEM/DSM paths --- #\n",
    "absolute_dem_path = None\n",
    "if include_dem:\n",
    "    absolute_dem_path = check_path(relative_dem_path, \"Generated DEM TIF\")\n",
    "absolute_dsm_path = None\n",
    "if include_dsm:\n",
    "    absolute_dsm_path = check_path(relative_dsm_path, \"Generated DSM TIF\")\n",
    "# --- END NEW --- #\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "\n",
    "# --- Calculate Bounds ---\n",
    "uhi_df = pd.read_csv(absolute_uhi_csv)\n",
    "required_cols = ['Longitude', 'Latitude']\n",
    "if not all(col in uhi_df.columns for col in required_cols):\n",
    "    raise ValueError(f\"UHI CSV must contain columns: {required_cols}\")\n",
    "bounds = [\n",
    "    uhi_df['Longitude'].min(),\n",
    "    uhi_df['Latitude'].min(),\n",
    "    uhi_df['Longitude'].max(),\n",
    "    uhi_df['Latitude'].max()\n",
    "]\n",
    "print(f\"Loaded bounds from {absolute_uhi_csv.name}: {bounds}\")\n",
    "\n",
    "# --- Central Config Dictionary for Logging --- #\n",
    "config = {\n",
    "    # Paths & Info\n",
<<<<<<< HEAD
    "    \"model_type\": \"UHINetCNN_HiResElev\", # Updated model type\n",
=======
    "    \"model_type\": \"UHINetCNN\",\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "    \"project_root\": project_root_str,\n",
    "    \"city_name\": city_name,\n",
    "    \"wandb_project_name\": wandb_project_name,\n",
    "    \"wander_run_name_prefix\": wander_run_name_prefix,\n",
    "    # Data Loading\n",
    "    \"resolution_m\": resolution_m,\n",
    "    \"include_lst\": include_lst,\n",
    "    \"uhi_csv\": str(relative_uhi_csv),\n",
    "    \"bronx_weather_csv\": str(absolute_bronx_weather_csv),\n",
    "    \"manhattan_weather_csv\": str(absolute_manhattan_weather_csv),\n",
    "    \"cloudless_mosaic_path\": str(absolute_cloudless_mosaic_path),\n",
    "    \"single_lst_median_path\": str(absolute_single_lst_median_path) if include_lst else None,\n",
<<<<<<< HEAD
    "    \"dem_path\": str(absolute_dem_path) if include_dem_branch else None, # Pass high-res path\n",
    "    \"dsm_path\": str(absolute_dsm_path) if include_dsm_branch else None, # Pass high-res path\n",
    "    \"high_res_nodata\": high_res_nodata, # Add nodata value\n",
=======
    "    # --- UPDATED DEM/DSM Paths --- #\n",
    "    \"include_dem\": include_dem,\n",
    "    \"include_dsm\": include_dsm,\n",
    "    \"dem_path\": str(absolute_dem_path) if include_dem else None, # Renamed parameter\n",
    "    \"dsm_path\": str(absolute_dsm_path) if include_dsm else None, # Renamed parameter\n",
    "    # --- END UPDATED --- #\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "    \"bounds\": bounds,\n",
    "    # Model Config\n",
    "    \"clay_model_size\": clay_model_size,\n",
    "    \"clay_bands\": clay_bands,\n",
    "    \"clay_platform\": clay_platform,\n",
    "    \"clay_gsd\": clay_gsd,\n",
    "    \"freeze_backbone\": freeze_backbone,\n",
    "    \"clay_checkpoint_path\": str(absolute_clay_checkpoint_path),\n",
    "    \"clay_metadata_path\": str(absolute_clay_metadata_path),\n",
    "    \"weather_channels\": weather_channels,\n",
    "    \"time_embed_dim\": time_embed_dim,\n",
    "    \"lst_channels\": lst_channels,\n",
<<<<<<< HEAD
    "    \"include_dem_branch\": include_dem_branch, # Added\n",
    "    \"include_dsm_branch\": include_dsm_branch, # Added\n",
    "    \"elevation_out_channels\": elevation_out_channels, # Added\n",
    "    \"proj_ch\": proj_ch,\n",
    "    \"head_type\": head_type,\n",
    "    # Simple CNN specific\n",
=======
    "    # DEM/DSM channels\n",
    "    \"dem_channels\": dem_channels if include_dem else 0,\n",
    "    \"dsm_channels\": dsm_channels if include_dsm else 0,\n",
    "    # Head config\n",
    "    \"proj_ch\": proj_ch,\n",
    "    \"head_type\": head_type,\n",
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "    \"cnn_hidden_dims\": cnn_hidden_dims,\n",
    "    \"cnn_kernel_size\": cnn_kernel_size,\n",
    "    \"cnn_dropout\": cnn_dropout,\n",
    "    \"unet_base_channels\": unet_base_channels,\n",
    "    \"unet_depth\": unet_depth,\n",
    "    # Training Hyperparameters\n",
    "    \"n_train_batches\": n_train_batches,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"loss_type\": loss_type,\n",
    "    \"patience\": patience,\n",
    "    \"device\": str(device)\n",
    "}\n",
    "\n",
    "print(\"\\nConfiguration dictionary created:\")\n",
<<<<<<< HEAD
    "# Use default=str for Path objects, handle potential np.nan for nodata\n",
    "def serialize_config(v):\n",
    "    if isinstance(v, Path):\n",
    "        return str(v)\n",
    "    if isinstance(v, float) and np.isnan(v):\n",
    "        return None # Represent NaN as null in JSON\n",
    "    return v\n",
    "print(json.dumps(config, indent=2, default=serialize_config))\n"
=======
    "print(json.dumps(config, indent=2, default=str)) # Use default=str for Path objects\n"
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd2dde-04dc-44fa-9c48-2840e2ec1e75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2abac67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 02:20:01,176 - INFO - Loading cloudless mosaic from /home/jupyter/MLC-Project/data/NYC/sat_files/sentinel_NYC_20210601_to_20210901_cloudless_mosaic.npy\n",
      "2025-04-30 02:20:01,254 - INFO - Loaded mosaic with 4 bands and shape (1119, 1278)\n",
      "2025-04-30 02:20:01,290 - INFO - Loading single LST median from: /home/jupyter/MLC-Project/data/NYC/sat_files/lst_NYC_median_20210601_to_20210901.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 02:20:01,391 - INFO - Loaded and normalized single LST median with shape (1, 1118, 969)\n",
      "/home/jupyter/MLC-Project/src/ingest/dataloader.py:143: FutureWarning: Parsed string \"2021-07-24 06:00:00 EDT\" included an un-recognized timezone \"EDT\". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.\n",
      "  dt_naive_or_aware = pd.to_datetime(self.bronx_weather['datetime'], errors='raise')\n",
      "/home/jupyter/MLC-Project/src/ingest/dataloader.py:169: FutureWarning: Parsed string \"2021-07-24 06:00:00 EDT\" included an un-recognized timezone \"EDT\". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.\n",
      "  dt_naive_or_aware = pd.to_datetime(self.manhattan_weather['datetime'], errors='raise')\n",
      "2025-04-30 02:20:01,401 - INFO - Loaded Bronx weather data: 169 records\n",
      "2025-04-30 02:20:01,402 - INFO - Loaded Manhattan weather data: 169 records\n",
      "2025-04-30 02:20:03,252 - INFO - Computed grid cell coordinates and closest station map\n",
      "2025-04-30 02:20:03,254 - INFO - Grid cells assigned to Bronx: 370359\n",
      "2025-04-30 02:20:03,256 - INFO - Grid cells assigned to Manhattan: 712983\n",
      "Precomputing UHI grids: 100%|██████████| 59/59 [00:00<00:00, 397.53it/s]\n",
      "2025-04-30 02:20:03,416 - INFO - Dataset initialized for NYC with 59 unique timestamps. LST included: True\n",
      "2025-04-30 02:20:03,417 - INFO - Target grid size (H, W): (1118, 969)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random dataset split: 36 training, 23 validation samples.\n",
      "Calculating UHI statistics from training data...\n",
      "Training UHI Mean: 1.0004, Std Dev: 0.0162\n",
      "Creating dataloaders...\n",
      "Data loading setup complete.\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "from torch.utils.data import Subset\n",
    "\n",
    "## IGNORE TIMEZONE WARNING: Timezone is first incorrectly loaded by pandas but then fixed in our dataloader.\n",
    "\n",
    "print(\"Initializing dataset...\")\n",
    "try:\n",
    "    # Note: averaging_window is needed by constructor but might not be used internally if single_lst_median_path is set\n",
    "    # Use a placeholder value if needed, or ensure the dataloader handles its optional usage.\n",
    "    placeholder_avg_window = 30 # Example placeholder\n",
    "\n",
    "    dataset = CityDataSet(\n",
    "        bounds=config['bounds'], # Use bounds from config\n",
    "        averaging_window=placeholder_avg_window, # Pass placeholder\n",
    "        resolution_m=config['resolution_m'], # Use config value\n",
    "        uhi_csv=absolute_uhi_csv,\n",
    "        # Use station weather CSVs\n",
    "        bronx_weather_csv=str(absolute_bronx_weather_csv),\n",
    "        manhattan_weather_csv=str(absolute_manhattan_weather_csv),\n",
    "        cloudless_mosaic_path=str(absolute_cloudless_mosaic_path),\n",
    "        data_dir=data_dir_base,\n",
    "        city_name=config['city_name'], # Use config value\n",
    "        include_lst=config['include_lst'], # Use config value\n",
    "        single_lst_median_path=str(absolute_single_lst_median_path) if config['include_lst'] else None,\n",
    "        # --- UPDATED: Pass DEM/DSM Paths using RENAMED parameters --- #\n",
    "        dem_path=str(absolute_dem_path) if config['include_dem'] else None,\n",
    "        dsm_path=str(absolute_dsm_path) if config['include_dsm'] else None,\n",
    "        # elevation_nodata can be omitted if using defaults in load_process_elevation for NYC data\n",
    "        # target_crs can be omitted if using defaults in load_process_elevation\n",
    "        # --- END UPDATED --- #\n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Dataset initialization failed: {e}\")\n",
    "    print(\"Ensure you have run the `notebooks/download_data.ipynb` notebook first to download and *generate* all required data (including DEM/DSM).\\\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error during dataset initialization: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Train/Val Split (Random) ---\n",
    "val_percent = 0.40\n",
    "n_samples = len(dataset)\n",
    "\n",
    "if n_samples < 10: # Handle very small datasets\n",
    "    print(f\"Warning: Dataset size ({n_samples}) is very small. Using all data for training.\")\n",
    "    n_val = 0\n",
    "    n_train = n_samples\n",
    "    train_ds = dataset # Use the whole dataset for training\n",
    "    val_ds = None      # No validation set\n",
    "else:\n",
    "    n_val = int(n_samples * val_percent)\n",
    "    n_train = n_samples - n_val\n",
    "    # Use random_split for a random split\n",
    "    train_ds, val_ds = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42)) # Seed for reproducibility\n",
    "\n",
    "print(f\"Random dataset split: {len(train_ds)} training, {len(val_ds) if val_ds else 0} validation samples.\")\n",
    "\n",
    "# --- Calculate UHI Mean and Std from Training Data ONLY ---\n",
    "print(\"Calculating UHI statistics from training data...\")\n",
    "all_train_targets = []\n",
    "# It's safer to iterate through the Subset to get the correctly indexed targets\n",
    "# Increase batch size for potentially faster calculation if memory allows\n",
    "calc_batch_size = min(64, len(train_ds)) if len(train_ds) > 0 else 1\n",
    "if len(train_ds) > 0:\n",
    "    temp_loader = DataLoader(train_ds, batch_size=calc_batch_size, shuffle=False, num_workers=0) # Use 0 workers for this calc\n",
    "    for batch in tqdm(temp_loader, desc=\"Calculating stats\"):\n",
    "        target_tensor = batch.get('target')\n",
    "        mask_tensor = batch.get('mask')\n",
    "        if target_tensor is None or mask_tensor is None:\n",
    "            logging.warning(\"Skipping batch in stats calculation due to missing target or mask.\")\n",
    "            continue\n",
    "        # Apply mask and collect valid UHI values\n",
    "        valid_targets = target_tensor[mask_tensor.bool()] # mask is already boolean\n",
    "        if valid_targets.numel() > 0: # Check if any valid targets exist\n",
    "            all_train_targets.append(valid_targets.cpu()) # Move to CPU before collecting\n",
    "else:\n",
    "    print(\"Training dataset is empty, skipping UHI statistics calculation.\")\n",
    "\n",
    "if not all_train_targets:\n",
    "     if len(train_ds) > 0:\n",
    "         raise ValueError(\"No valid training targets found to calculate UHI statistics. Check masks and data.\")\n",
    "     else:\n",
    "         # Handle case with no training data at all\n",
    "         print(\"Warning: No training data. Setting UHI stats to 0 and 1.\")\n",
    "         uhi_mean = 0.0\n",
    "         uhi_std = 1.0\n",
    "else:\n",
    "    all_train_targets_tensor = torch.cat(all_train_targets)\n",
    "    uhi_mean = all_train_targets_tensor.mean().item()\n",
    "    uhi_std = all_train_targets_tensor.std().item()\n",
    "    # Add a small epsilon to std to prevent division by zero if all targets are identical\n",
    "    uhi_std = uhi_std if uhi_std > 1e-6 else 1.0\n",
    "\n",
    "print(f\"Training UHI Mean: {uhi_mean:.4f}, Std Dev: {uhi_std:.4f}\")\n",
    "\n",
    "# Store in config for easy passing (or pass separately)\n",
    "config['uhi_mean'] = uhi_mean\n",
    "config['uhi_std'] = uhi_std\n",
    "\n",
    "print(\"Creating dataloaders...\")\n",
    "# Calculate batch size dynamically based on number of training batches desired\n",
    "train_batch_size = max(1, len(train_ds) // config['n_train_batches']) if len(train_ds) > 0 else 1\n",
    "val_batch_size = len(val_ds) if val_ds and len(val_ds) > 0 else 1 # Load validation set in one batch if possible\n",
    "print(f\"Using Train Batch Size: {train_batch_size}\")\n",
    "\n",
    "# Shuffle training data loader, but not validation\n",
    "train_loader = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True, num_workers=config['num_workers'], pin_memory=True, drop_last=True) if len(train_ds) > 0 else None\n",
    "val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=config['num_workers'], pin_memory=True) if val_ds and len(val_ds) > 0 else None\n",
    "\n",
    "print(\"Data loading setup complete.\")\n",
    "\n",
    "# Verify Dataloader Output - Check for new DEM/DSM keys if included\n",
    "if train_loader:\n",
    "    try:\n",
    "        first_batch = next(iter(train_loader))\n",
    "        print(\"\\nFirst training batch keys:\", list(first_batch.keys()))\n",
    "        # Print shapes to verify\n",
    "        for k, v in first_batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                print(f\"  {k}: {v.shape}, dtype={v.dtype}\")\n",
    "            else:\n",
    "                 print(f\"  {k}: type={type(v)}\")\n",
    "        # Optional: Add specific shape checks for dem/dsm if needed\n",
    "        if config.get('include_dem', False) and 'dem' not in first_batch:\n",
    "            logging.warning(\"Configuration includes DEM, but 'dem' key missing from batch.\")\n",
    "        if config.get('include_dsm', False) and 'dsm' not in first_batch:\n",
    "             logging.warning(\"Configuration includes DSM, but 'dsm' key missing from batch.\")\n",
    "\n",
    "    except StopIteration:\n",
    "        print(\"\\nCould not get first batch, training loader might be empty.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError inspecting first batch: {e}\")\n",
    "else:\n",
    "    print(\"\\nTraining loader is not available (likely no training data).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06690edc",
   "metadata": {},
   "source": [
>>>>>>> 448c9806d4ef2cfbd0e746f377b21adbcc7f8df5
    "model = UHINetCNN(\n",
    "    clay_checkpoint_path=str(absolute_clay_checkpoint_path),\n",
    "    clay_metadata_path=str(absolute_clay_metadata_path),\n",
    "    weather_channels=config[\"weather_channels\"],\n",
    "    freeze_backbone=config[\"freeze_backbone\"],\n",
    "    # --- Args with defaults ---\n",
    "    proj_ch=config[\"proj_ch\"],\n",
    "    clay_model_size=config[\"clay_model_size\"],\n",
    "    clay_bands=config[\"clay_bands\"],\n",
    "    clay_platform=config[\"clay_platform\"],\n",
    "    clay_gsd=config[\"clay_gsd\"],\n",
    "    # LST args\n",
    "    lst_channels=config[\"lst_channels\"],\n",
    "    use_lst=config[\"include_lst\"],\n",
    "    # --- Head Selection & Args ---\n",
    "    head_type=config[\"head_type\"],\n",
    "    # SimpleCNN Head Args\n",
    "    cnn_hidden_dims=config[\"cnn_hidden_dims\"],\n",
    "    cnn_kernel_size=config[\"cnn_kernel_size\"],\n",
    "    cnn_dropout=config[\"cnn_dropout\"],\n",
    "    # UNet Head Args\n",
    "    unet_base_channels=config[\"unet_base_channels\"],\n",
    "    unet_depth=config[\"unet_depth\"],\n",
    "    # --- High-Res Elevation Branch Args --- #\n",
    "    include_dem_branch=config[\"include_dem_branch\"],\n",
    "    include_dsm_branch=config[\"include_dsm_branch\"],\n",
    "    elevation_out_channels=config[\"elevation_out_channels\"]\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06690edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar', best_filename='model_best.pth.tar'):\n",
    "    \"\"\"Saves model checkpoint.\"\"\"\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, best_filename)\n",
    "        print(f\"Saved new best model to {best_filename}\")\n",
    "        \n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, device, uhi_mean, uhi_std, config):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_targets_unnorm = []\n",
    "    all_preds_unnorm = []\n",
    "    num_batches = 0\n",
    "    progress_bar = tqdm(dataloader, desc='Training', leave=False)\n",
    "\n",
    "    # Get config flags for convenience\n",
    "    use_lst_flag = config.get('include_lst', False)\n",
    "    include_dem_branch_flag = config.get('include_dem_branch', False)\n",
    "    include_dsm_branch_flag = config.get('include_dsm_branch', False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # --- Check keys and move to device ---\n",
    "        # Mandatory keys from dataloader\n",
    "        required_keys = ['cloudless_mosaic', 'weather_grid', 'target', 'mask', 'norm_latlon', 'norm_timestamp']\n",
    "        # Optional keys based on config\n",
    "        if use_lst_flag: required_keys.append('lst_median')\n",
    "        if include_dem_branch_flag: required_keys.append('high_res_dem')\n",
    "        if include_dsm_branch_flag: required_keys.append('high_res_dsm')\n",
    "        # time_embedding might still be present from older versions\n",
    "        \n",
    "        if not all(key in batch for key in required_keys):\n",
    "            missing = [key for key in required_keys if key not in batch]\n",
    "            logging.warning(f\"Skipping batch due to missing keys: {missing}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Mandatory\n",
    "            cloudless_mosaic = batch[\"cloudless_mosaic\"].to(device)\n",
    "            weather = batch[\"weather_grid\"].to(device) # Key from dataloader\n",
    "            target_unnorm = batch[\"target\"].to(device)\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "            norm_latlon_input = batch[\"norm_latlon\"].to(device)\n",
    "            norm_time_input = batch[\"norm_timestamp\"].to(device)\n",
    "            \n",
    "            # Optional\n",
    "            static_lst_input = batch[\"lst_median\"].to(device) if use_lst_flag else None\n",
    "            high_res_dem_input = batch[\"high_res_dem\"].to(device) if include_dem_branch_flag else None\n",
    "            high_res_dsm_input = batch[\"high_res_dsm\"].to(device) if include_dsm_branch_flag else None\n",
    "\n",
    "            # Get target H, W for the forward pass (low-res)\n",
    "            target_h, target_w = target_unnorm.shape[2], target_unnorm.shape[3]\n",
    "            target_h_w_tuple = (target_h, target_w)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error moving batch to device: {e}\")\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            # --- Forward Pass - Use correct argument names --- #\n",
    "            prediction_norm = model(\n",
    "                cloudless_mosaic=cloudless_mosaic,\n",
    "                norm_time_tensor=norm_time_input,\n",
    "                norm_latlon_tensor=norm_latlon_input,\n",
    "                weather=weather,\n",
    "                target_h_w=target_h_w_tuple,\n",
    "                static_lst=static_lst_input,\n",
    "                high_res_dem=high_res_dem_input, # Pass high-res data\n",
    "                high_res_dsm=high_res_dsm_input  # Pass high-res data\n",
    "            ) # Shape (B, 1, H_low_res, W_low_res)\n",
    "\n",
    "            # --- Loss Calculation --- #\n",
    "            prediction_norm_final = prediction_norm.squeeze(1) # Shape (B, H_low_res, W_low_res)\n",
    "            target_norm = (target_unnorm.squeeze(1) - uhi_mean) / uhi_std # Normalize target (B, H_low_res, W_low_res)\n",
    "            loss = loss_fn(prediction_norm_final, target_norm, mask.squeeze(1)) # Use mask (B, H_low_res, W_low_res)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                logging.warning(\"NaN loss detected, skipping backward pass.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # --- Accumulate for Metrics (using unnormalized values) ---\n",
    "            prediction_unnorm = prediction_norm_final * uhi_std + uhi_mean\n",
    "            mask_bool = mask.squeeze(1).bool() # Get boolean mask (B, H, W)\n",
    "            all_preds_unnorm.append(prediction_unnorm[mask_bool].detach().cpu())\n",
    "            all_targets_unnorm.append(target_unnorm.squeeze(1)[mask_bool].detach().cpu())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            logging.error(f\"Runtime error during training: {e}\")\n",
    "            if \"out of memory\" in str(e):\n",
    "                logging.error(\"CUDA out of memory. Try reducing batch size.\")\n",
    "            continue # Skip batch\n",
    "        except TypeError as e: # Catch specific TypeError from forward mismatch\n",
    "            logging.error(f\"TypeError during model forward pass: {e}. Check argument names and types.\")\n",
    "            continue # Skip batch\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error during training step: {e}\", exc_info=True)\n",
    "            continue # Skip batch\n",
    "\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "    # Calculate metrics on unnormalized, masked data for the whole epoch\n",
    "    if all_targets_unnorm:\n",
    "        all_targets_unnorm_flat = torch.cat(all_targets_unnorm).numpy()\n",
    "        all_preds_unnorm_flat = torch.cat(all_preds_unnorm).numpy()\n",
    "        valid_idx = ~np.isnan(all_targets_unnorm_flat) & ~np.isnan(all_preds_unnorm_flat)\n",
    "        if np.sum(valid_idx) > 0: # Check if there are any valid pixels\n",
    "            rmse = math.sqrt(mean_squared_error(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx]))\n",
    "            r2 = r2_score(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx])\n",
    "        else:\n",
    "             logging.warning(\"No valid pixels found for calculating metrics in training epoch.\")\n",
    "             rmse = float('nan'); r2 = float('nan')\n",
    "    else:\n",
    "        logging.warning(\"No targets accumulated for calculating metrics in training epoch.\")\n",
    "        rmse = float('nan'); r2 = float('nan')\n",
    "\n",
    "    return avg_loss, rmse, r2\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, loss_fn, device, uhi_mean, uhi_std, config):\n",
    "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_targets_unnorm = []\n",
    "    all_preds_unnorm = []\n",
    "    num_batches = 0\n",
    "    progress_bar = tqdm(dataloader, desc='Validation', leave=False)\n",
    "\n",
    "    # Get config flags for convenience\n",
    "    use_lst_flag = config.get('include_lst', False)\n",
    "    include_dem_branch_flag = config.get('include_dem_branch', False)\n",
    "    include_dsm_branch_flag = config.get('include_dsm_branch', False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            # --- Check keys and move to device (same as train_epoch) ---\n",
    "            required_keys = ['cloudless_mosaic', 'weather_grid', 'target', 'mask', 'norm_latlon', 'norm_timestamp']\n",
    "            if use_lst_flag: required_keys.append('lst_median')\n",
    "            if include_dem_branch_flag: required_keys.append('high_res_dem')\n",
    "            if include_dsm_branch_flag: required_keys.append('high_res_dsm')\n",
    "\n",
    "            if not all(key in batch for key in required_keys):\n",
    "                missing = [key for key in required_keys if key not in batch]\n",
    "                logging.warning(f\"Skipping validation batch due to missing keys: {missing}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Mandatory\n",
    "                cloudless_mosaic = batch[\"cloudless_mosaic\"].to(device)\n",
    "                weather = batch[\"weather_grid\"].to(device)\n",
    "                target_unnorm = batch[\"target\"].to(device)\n",
    "                mask = batch[\"mask\"].to(device)\n",
    "                norm_latlon_input = batch[\"norm_latlon\"].to(device)\n",
    "                norm_time_input = batch[\"norm_timestamp\"].to(device)\n",
    "                \n",
    "                # Optional\n",
    "                static_lst_input = batch[\"lst_median\"].to(device) if use_lst_flag else None\n",
    "                high_res_dem_input = batch[\"high_res_dem\"].to(device) if include_dem_branch_flag else None\n",
    "                high_res_dsm_input = batch[\"high_res_dsm\"].to(device) if include_dsm_branch_flag else None\n",
    "                \n",
    "                # Get target H, W for the forward pass (low-res)\n",
    "                target_h, target_w = target_unnorm.shape[2], target_unnorm.shape[3]\n",
    "                target_h_w_tuple = (target_h, target_w)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error moving validation batch to device: {e}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # --- Forward Pass --- #\n",
    "                prediction_norm = model(\n",
    "                    cloudless_mosaic=cloudless_mosaic,\n",
    "                    norm_time_tensor=norm_time_input,\n",
    "                    norm_latlon_tensor=norm_latlon_input,\n",
    "                    weather=weather,\n",
    "                    target_h_w=target_h_w_tuple,\n",
    "                    static_lst=static_lst_input,\n",
    "                    high_res_dem=high_res_dem_input,\n",
    "                    high_res_dsm=high_res_dsm_input\n",
    "                )\n",
    "\n",
    "                # --- Loss Calculation --- #\n",
    "                prediction_norm_final = prediction_norm.squeeze(1)\n",
    "                target_norm = (target_unnorm.squeeze(1) - uhi_mean) / uhi_std\n",
    "                loss = loss_fn(prediction_norm_final, target_norm, mask.squeeze(1))\n",
    "\n",
    "                if torch.isnan(loss):\n",
    "                    logging.warning(\"NaN validation loss detected, skipping batch.\")\n",
    "                    continue\n",
    "\n",
    "                # --- Accumulate for Metrics --- #\n",
    "                prediction_unnorm = prediction_norm_final * uhi_std + uhi_mean\n",
    "                mask_bool = mask.squeeze(1).bool()\n",
    "                all_preds_unnorm.append(prediction_unnorm[mask_bool].detach().cpu())\n",
    "                all_targets_unnorm.append(target_unnorm.squeeze(1)[mask_bool].detach().cpu())\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "            except TypeError as e: # Catch specific TypeError\n",
    "                 logging.error(f\"TypeError during validation model forward pass: {e}. Check arguments.\")\n",
    "                 continue # Skip batch\n",
    "            except Exception as e:\n",
    "                 logging.error(f\"Error during validation step: {e}\", exc_info=True)\n",
    "                 continue # Skip batch on other errors\n",
    "\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "    # Calculate metrics on unnormalized, masked data for the whole epoch\n",
    "    if all_targets_unnorm:\n",
    "        all_targets_unnorm_flat = torch.cat(all_targets_unnorm).numpy()\n",
    "        all_preds_unnorm_flat = torch.cat(all_preds_unnorm).numpy()\n",
    "        valid_idx = ~np.isnan(all_targets_unnorm_flat) & ~np.isnan(all_preds_unnorm_flat)\n",
    "        if np.sum(valid_idx) > 0: # Check if there are any valid pixels\n",
    "             rmse = math.sqrt(mean_squared_error(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx]))\n",
    "             r2 = r2_score(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx])\n",
    "        else:\n",
    "             logging.warning(\"No valid pixels found for calculating metrics in validation epoch.\")\n",
    "             rmse = float('nan'); r2 = float('nan')\n",
    "    else:\n",
    "        logging.warning(\"No targets accumulated for calculating metrics in validation epoch.\")\n",
    "        rmse = float('nan'); r2 = float('nan')\n",
    "\n",
    "    return avg_loss, rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cce9967-2cc3-4e92-8b91-eaff4016724d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually loading checkpoint: /home/jupyter/MLC-Project/notebooks/clay-v1.5.ckpt\n",
      "Instantiating ClayMAEModule manually...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 02:20:19,375 - INFO - Loading pretrained weights from Hugging Face hub (timm/vit_large_patch14_reg4_dinov2.lvd142m)\n",
      "2025-04-30 02:20:19,472 - INFO - [timm/vit_large_patch14_reg4_dinov2.lvd142m] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading state_dict manually into self.model.model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 02:20:23,444 - INFO - Clay backbone frozen.\n",
      "2025-04-30 02:20:23,454 - INFO - UHINetCNN initialized (Feedforward CNN with Dynamic Clay):\n",
      "2025-04-30 02:20:23,454 - INFO -   Clay Embed Dim: 1024 -> Proj Dim: 64\n",
      "2025-04-30 02:20:23,455 - INFO -   Use LST: True (Channels: 1)\n",
      "2025-04-30 02:20:23,455 - INFO -   CNN Input Dim (Proj Dyn Clay [+ LST] + Weather): 71\n",
      "2025-04-30 02:20:23,456 - INFO -   CNN Hidden Dims: [32, 16, 8] (with BatchNorm)\n",
      "2025-04-30 02:20:23,456 - INFO -   CNN Dropout Rate: 0.3\n",
      "2025-04-30 02:20:23,457 - INFO -   CNN Output Dim (Before Final BN/Regressor): 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Overriding patch size from hparams. Using fixed patch_size = 16\n",
      "Clay model properties: model_size=large, embed_dim=1024, patch_size=16 (patch_size OVERRIDDEN)\n",
      "Normalization prepared for bands: ['blue', 'green', 'red', 'nir']\n"
     ]
    }
   ],
   "source": [
    "model = UHINetCNN(\n",
    "    clay_checkpoint_path=str(absolute_clay_checkpoint_path),\n",
    "    clay_metadata_path=str(absolute_clay_metadata_path),\n",
    "    weather_channels=config[\"weather_channels\"],\n",
    "    proj_ch=config[\"proj_ch\"],\n",
    "    clay_model_size=config[\"clay_model_size\"],\n",
    "    clay_bands=config[\"clay_bands\"],\n",
    "    clay_platform=config[\"clay_platform\"],\n",
    "    clay_gsd=config[\"clay_gsd\"],\n",
    "    lst_channels=config[\"lst_channels\"],\n",
    "    use_lst=config[\"include_lst\"],\n",
    "    cnn_hidden_dims=config[\"cnn_hidden_dims\"],\n",
    "    cnn_kernel_size=config[\"cnn_kernel_size\"],\n",
    "    cnn_dropout=cnn_dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc639c88-302c-4d12-a717-89683df94156",
   "metadata": {},
   "source": [
    "## Helper Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b3749-8013-4b55-9478-722d87783b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar', best_filename='model_best.pth.tar'):\n",
    "    \"\"\"Saves model checkpoint.\"\"\"\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, best_filename)\n",
    "        print(f\"Saved new best model to {best_filename}\")\n",
    "        \n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, device, uhi_mean, uhi_std):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_targets_unnorm = []\n",
    "    all_preds_unnorm = []\n",
    "    num_batches = 0\n",
    "    progress_bar = tqdm(dataloader, desc='Training', leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # --- Check keys and move to device ---\n",
    "        # Using the keys returned by the updated dataloader\n",
    "        required_keys = ['cloudless_mosaic', 'weather_seq', 'time_emb_seq', 'target', 'mask', 'norm_latlon', 'norm_time']\n",
    "        if include_lst: # Use config value\n",
    "            required_keys.append('lst_seq')\n",
    "        if not all(key in batch for key in required_keys):\n",
    "            missing = [key for key in required_keys if key not in batch]\n",
    "            logging.warning(f\"Skipping batch due to missing keys: {missing}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cloudless_mosaic = batch[\"cloudless_mosaic\"].to(device)\n",
    "            weather = batch[\"weather_seq\"].to(device) # Key from dataloader\n",
    "            # lst_seq key is correct from dataloader\n",
    "            static_lst_input = batch[\"lst_seq\"] if include_lst and \"lst_seq\" in batch else None\n",
    "            if static_lst_input is not None: static_lst_input = static_lst_input.to(device)\n",
    "            # time_emb_seq is needed for GRU model, not directly for CNN forward\n",
    "            # Keep it for potential future use or remove if definitely not needed\n",
    "            # time_emb_seq = batch[\"time_emb_seq\"].to(device)\n",
    "            target_unnorm = batch[\"target\"].to(device)\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "            norm_latlon_input = batch[\"norm_latlon\"].to(device) # Key from dataloader\n",
    "            norm_time_input = batch[\"norm_time\"].to(device)    # Key from dataloader\n",
    "\n",
    "            # Get target H, W for the forward pass\n",
    "            target_h, target_w = target_unnorm.shape[1], target_unnorm.shape[2]\n",
    "            target_h_w_tuple = (target_h, target_w)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error moving batch to device: {e}\")\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            # --- Forward Pass - Use correct argument names ---\n",
    "            prediction_norm = model(\n",
    "                cloudless_mosaic=cloudless_mosaic,\n",
    "                norm_time_tensor=norm_time_input,    # Match forward signature\n",
    "                norm_latlon_tensor=norm_latlon_input, # Match forward signature\n",
    "                weather=weather,                     # Match forward signature\n",
    "                target_h_w=target_h_w_tuple,         # Pass target shape\n",
    "                static_lst=static_lst_input          # Match forward signature\n",
    "            ) # Shape (B, 1, H_orig, W_orig)\n",
    "\n",
    "            # --- Loss Calculation (No resizing needed, model outputs at target size) ---\n",
    "            prediction_norm_final = prediction_norm.squeeze(1) # Shape (B, H_orig, W_orig)\n",
    "\n",
    "            # Normalize Target for Loss Calculation\n",
    "            target_norm = (target_unnorm - uhi_mean) / uhi_std\n",
    "\n",
    "            # Calculate Loss (using normalized values)\n",
    "            loss = loss_fn(prediction_norm_final, target_norm, mask)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                logging.warning(\"NaN loss detected, skipping backward pass.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # --- Accumulate for Metrics (using unnormalized values) ---\n",
    "            # Unnormalize prediction\n",
    "            prediction_unnorm = prediction_norm_final * uhi_std + uhi_mean\n",
    "            # Only append valid pixels based on the mask\n",
    "            all_preds_unnorm.append(prediction_unnorm[mask.bool()].detach().cpu())\n",
    "            all_targets_unnorm.append(target_unnorm[mask.bool()].detach().cpu())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            logging.error(f\"Runtime error during training: {e}\")\n",
    "            if \"out of memory\" in str(e):\n",
    "                logging.error(\"CUDA out of memory. Try reducing batch size.\")\n",
    "            continue # Skip batch\n",
    "        except TypeError as e: # Catch specific TypeError from forward mismatch\n",
    "            logging.error(f\"TypeError during model forward pass: {e}. Check argument names and types.\")\n",
    "            # You might want to inspect the batch content here if needed\n",
    "            # print(\"Batch keys:\", batch.keys())\n",
    "            # for k,v in batch.items(): print(f\"{k} shape: {v.shape} dtype: {v.dtype}\")\n",
    "            continue # Skip batch\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error during training step: {e}\", exc_info=True)\n",
    "            continue # Skip batch\n",
    "\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "    # Calculate metrics on unnormalized, masked data for the whole epoch\n",
    "    if all_targets_unnorm:\n",
    "        all_targets_unnorm_flat = torch.cat(all_targets_unnorm).numpy()\n",
    "        all_preds_unnorm_flat = torch.cat(all_preds_unnorm).numpy()\n",
    "        # Ensure no NaNs slipped through\n",
    "        valid_idx = ~np.isnan(all_targets_unnorm_flat) & ~np.isnan(all_preds_unnorm_flat)\n",
    "        if np.sum(valid_idx) > 0: # Check if there are any valid pixels\n",
    "            rmse = math.sqrt(mean_squared_error(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx]))\n",
    "            r2 = r2_score(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx])\n",
    "        else:\n",
    "             logging.warning(\"No valid pixels found for calculating metrics in training epoch.\")\n",
    "             rmse = float('nan')\n",
    "             r2 = float('nan')\n",
    "    else:\n",
    "        logging.warning(\"No targets accumulated for calculating metrics in training epoch.\")\n",
    "        rmse = float('nan')\n",
    "        r2 = float('nan')\n",
    "\n",
    "    return avg_loss, rmse, r2\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, loss_fn, device, uhi_mean, uhi_std):\n",
    "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_targets_unnorm = []\n",
    "    all_preds_unnorm = []\n",
    "    num_batches = 0\n",
    "    progress_bar = tqdm(dataloader, desc='Validation', leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            # --- Check keys and move to device (same as train_epoch) ---\n",
    "            required_keys = ['cloudless_mosaic', 'weather_seq', 'time_emb_seq', 'target', 'mask', 'norm_latlon', 'norm_time']\n",
    "            if include_lst: # Use config value\n",
    "                required_keys.append('lst_seq')\n",
    "            if not all(key in batch for key in required_keys):\n",
    "                missing = [key for key in required_keys if key not in batch]\n",
    "                logging.warning(f\"Skipping validation batch due to missing keys: {missing}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                cloudless_mosaic = batch[\"cloudless_mosaic\"].to(device)\n",
    "                weather = batch[\"weather_seq\"].to(device) # Key from dataloader\n",
    "                static_lst_input = batch[\"lst_seq\"] if include_lst and \"lst_seq\" in batch else None\n",
    "                if static_lst_input is not None: static_lst_input = static_lst_input.to(device)\n",
    "                target_unnorm = batch[\"target\"].to(device)\n",
    "                mask = batch[\"mask\"].to(device)\n",
    "                norm_latlon_input = batch[\"norm_latlon\"].to(device) # Key from dataloader\n",
    "                norm_time_input = batch[\"norm_time\"].to(device)    # Key from dataloader\n",
    "\n",
    "                # Get target H, W for the forward pass\n",
    "                target_h, target_w = target_unnorm.shape[1], target_unnorm.shape[2]\n",
    "                target_h_w_tuple = (target_h, target_w)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error moving validation batch to device: {e}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # --- Forward Pass - Use correct argument names ---\n",
    "                prediction_norm = model(\n",
    "                    cloudless_mosaic=cloudless_mosaic,\n",
    "                    norm_time_tensor=norm_time_input,    # Match forward signature\n",
    "                    norm_latlon_tensor=norm_latlon_input, # Match forward signature\n",
    "                    weather=weather,                     # Match forward signature\n",
    "                    target_h_w=target_h_w_tuple,         # Pass target shape\n",
    "                    static_lst=static_lst_input          # Match forward signature\n",
    "                ) # Shape (B, 1, H_orig, W_orig)\n",
    "\n",
    "                # --- Loss Calculation (No resizing needed) ---\n",
    "                prediction_norm_final = prediction_norm.squeeze(1) # Shape (B, H_orig, W_orig)\n",
    "\n",
    "                # Normalize Target for Loss Calculation\n",
    "                target_norm = (target_unnorm - uhi_mean) / uhi_std\n",
    "\n",
    "                # Calculate Loss (using normalized values)\n",
    "                loss = loss_fn(prediction_norm_final, target_norm, mask)\n",
    "\n",
    "                if torch.isnan(loss):\n",
    "                    logging.warning(\"NaN validation loss detected, skipping batch.\")\n",
    "                    continue\n",
    "\n",
    "                # --- Accumulate for Metrics (using unnormalized values) ---\n",
    "                prediction_unnorm = prediction_norm_final * uhi_std + uhi_mean\n",
    "                # Only append valid pixels based on the mask\n",
    "                all_preds_unnorm.append(prediction_unnorm[mask.bool()].detach().cpu())\n",
    "                all_targets_unnorm.append(target_unnorm[mask.bool()].detach().cpu())\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "            except TypeError as e: # Catch specific TypeError\n",
    "                 logging.error(f\"TypeError during validation model forward pass: {e}. Check arguments.\")\n",
    "                 continue # Skip batch\n",
    "            except Exception as e:\n",
    "                 logging.error(f\"Error during validation step: {e}\", exc_info=True)\n",
    "                 continue # Skip batch on other errors\n",
    "\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "    # Calculate metrics on unnormalized, masked data for the whole epoch\n",
    "    if all_targets_unnorm:\n",
    "        all_targets_unnorm_flat = torch.cat(all_targets_unnorm).numpy()\n",
    "        all_preds_unnorm_flat = torch.cat(all_preds_unnorm).numpy()\n",
    "        valid_idx = ~np.isnan(all_targets_unnorm_flat) & ~np.isnan(all_preds_unnorm_flat)\n",
    "        if np.sum(valid_idx) > 0: # Check if there are any valid pixels\n",
    "             rmse = math.sqrt(mean_squared_error(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx]))\n",
    "             r2 = r2_score(all_targets_unnorm_flat[valid_idx], all_preds_unnorm_flat[valid_idx])\n",
    "        else:\n",
    "             logging.warning(\"No valid pixels found for calculating metrics in validation epoch.\")\n",
    "             rmse = float('nan')\n",
    "             r2 = float('nan')\n",
    "    else:\n",
    "        logging.warning(\"No targets accumulated for calculating metrics in validation epoch.\")\n",
    "        rmse = float('nan')\n",
    "        r2 = float('nan')\n",
    "\n",
    "    return avg_loss, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d733113-cb81-4972-bdff-5e1cd1a4d691",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab087292-f6cb-4c31-8db0-6ae9bb6223f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model UHINetCNN initialized on cuda\n",
      "Checkpoints and logs will be saved to: /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023\n",
      "Using Training UHI Mean: 1.0004, Std Dev: 0.0162 for normalization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnava1304\u001b[0m (\u001b[33marnava1304-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/MLC-Project/notebooks/wandb/run-20250430_022024-1hnl57gu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/1hnl57gu' target=\"_blank\">NYC_UHINetCNN_20250430_022023</a></strong> to <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj' target=\"_blank\">https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/1hnl57gu' target=\"_blank\">https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/1hnl57gu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb initialized for run: NYC_UHINetCNN_20250430_022023\n",
      "Saved local configuration to config.json\n",
      "Starting CNN training...\n",
      "--- Epoch 1/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=645.8097 RMSE=0.0169 R2=-0.0923 | Val Loss=3226.9849 RMSE=0.0165 R2=-0.0316\n",
      "New best validation R^2: -0.0316\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 2/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=619.4320 RMSE=0.0166 R2=-0.0477 | Val Loss=3201.6125 RMSE=0.0164 R2=-0.0235\n",
      "New best validation R^2: -0.0235\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 3/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=592.4688 RMSE=0.0162 R2=-0.0021 | Val Loss=3103.2617 RMSE=0.0162 R2=0.0080\n",
      "New best validation R^2: 0.0080\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 4/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=608.3326 RMSE=0.0164 R2=-0.0289 | Val Loss=2994.3579 RMSE=0.0159 R2=0.0428\n",
      "New best validation R^2: 0.0428\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 5/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=555.4505 RMSE=0.0157 R2=0.0605 | Val Loss=2895.1689 RMSE=0.0156 R2=0.0745\n",
      "New best validation R^2: 0.0745\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 6/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=520.1677 RMSE=0.0152 R2=0.1202 | Val Loss=2928.8545 RMSE=0.0157 R2=0.0637\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 7/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=596.9733 RMSE=0.0163 R2=-0.0097 | Val Loss=2853.7822 RMSE=0.0155 R2=0.0877\n",
      "New best validation R^2: 0.0877\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 8/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=532.3227 RMSE=0.0154 R2=0.0996 | Val Loss=2936.8237 RMSE=0.0157 R2=0.0612\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 9/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=566.1273 RMSE=0.0158 R2=0.0424 | Val Loss=2793.0508 RMSE=0.0154 R2=0.1071\n",
      "New best validation R^2: 0.1071\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 10/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=534.8112 RMSE=0.0154 R2=0.0954 | Val Loss=2801.7456 RMSE=0.0154 R2=0.1043\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 11/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=562.8188 RMSE=0.0158 R2=0.0480 | Val Loss=2649.6572 RMSE=0.0150 R2=0.1530\n",
      "New best validation R^2: 0.1530\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 12/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=535.5470 RMSE=0.0154 R2=0.0942 | Val Loss=2979.5686 RMSE=0.0159 R2=0.0475\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 13/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=554.7834 RMSE=0.0157 R2=0.0616 | Val Loss=2787.3311 RMSE=0.0153 R2=0.1090\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 14/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=505.4470 RMSE=0.0150 R2=0.1451 | Val Loss=2786.1643 RMSE=0.0153 R2=0.1093\n",
      "No improvement in validation R^2 for 3 epochs.\n",
      "--- Epoch 15/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=554.4417 RMSE=0.0157 R2=0.0622 | Val Loss=2901.9517 RMSE=0.0157 R2=0.0723\n",
      "No improvement in validation R^2 for 4 epochs.\n",
      "--- Epoch 16/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=508.4681 RMSE=0.0150 R2=0.1400 | Val Loss=2693.0142 RMSE=0.0151 R2=0.1391\n",
      "No improvement in validation R^2 for 5 epochs.\n",
      "--- Epoch 17/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=518.6981 RMSE=0.0152 R2=0.1227 | Val Loss=2603.2144 RMSE=0.0148 R2=0.1678\n",
      "New best validation R^2: 0.1678\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 18/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=544.8151 RMSE=0.0155 R2=0.0785 | Val Loss=2575.1655 RMSE=0.0147 R2=0.1768\n",
      "New best validation R^2: 0.1768\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 19/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=507.7743 RMSE=0.0150 R2=0.1411 | Val Loss=2620.6755 RMSE=0.0149 R2=0.1622\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 20/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=503.7513 RMSE=0.0149 R2=0.1479 | Val Loss=2610.5540 RMSE=0.0148 R2=0.1655\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 21/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=527.9740 RMSE=0.0153 R2=0.1070 | Val Loss=2656.1699 RMSE=0.0150 R2=0.1509\n",
      "No improvement in validation R^2 for 3 epochs.\n",
      "--- Epoch 22/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=468.0458 RMSE=0.0144 R2=0.2083 | Val Loss=2524.9971 RMSE=0.0146 R2=0.1928\n",
      "New best validation R^2: 0.1928\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 23/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=470.5060 RMSE=0.0144 R2=0.2042 | Val Loss=2646.7505 RMSE=0.0150 R2=0.1539\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 24/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=470.8963 RMSE=0.0144 R2=0.2035 | Val Loss=2551.9546 RMSE=0.0147 R2=0.1842\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 25/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=428.7389 RMSE=0.0138 R2=0.2748 | Val Loss=2549.7131 RMSE=0.0147 R2=0.1849\n",
      "No improvement in validation R^2 for 3 epochs.\n",
      "--- Epoch 26/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=479.1599 RMSE=0.0146 R2=0.1895 | Val Loss=2494.6724 RMSE=0.0145 R2=0.2025\n",
      "New best validation R^2: 0.2025\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 27/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=462.3014 RMSE=0.0143 R2=0.2181 | Val Loss=2327.6934 RMSE=0.0140 R2=0.2559\n",
      "New best validation R^2: 0.2559\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 28/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=441.2404 RMSE=0.0140 R2=0.2537 | Val Loss=2539.5195 RMSE=0.0146 R2=0.1882\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 29/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=445.1794 RMSE=0.0140 R2=0.2470 | Val Loss=2350.2019 RMSE=0.0141 R2=0.2487\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 30/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=471.6626 RMSE=0.0145 R2=0.2022 | Val Loss=2426.2075 RMSE=0.0143 R2=0.2244\n",
      "No improvement in validation R^2 for 3 epochs.\n",
      "--- Epoch 31/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=444.9828 RMSE=0.0140 R2=0.2474 | Val Loss=2549.3318 RMSE=0.0147 R2=0.1850\n",
      "No improvement in validation R^2 for 4 epochs.\n",
      "--- Epoch 32/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss=454.2806 RMSE=0.0142 R2=0.2316 | Val Loss=2284.2578 RMSE=0.0139 R2=0.2698\n",
      "New best validation R^2: 0.2698\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 33/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=442.3483 RMSE=0.0140 R2=0.2518 | Val Loss=2414.1567 RMSE=0.0143 R2=0.2282\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 34/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=478.2115 RMSE=0.0146 R2=0.1911 | Val Loss=2426.7026 RMSE=0.0143 R2=0.2242\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 35/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss=457.2233 RMSE=0.0142 R2=0.2266 | Val Loss=2224.4580 RMSE=0.0137 R2=0.2889\n",
      "New best validation R^2: 0.2889\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 36/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=430.4526 RMSE=0.0138 R2=0.2719 | Val Loss=2388.2051 RMSE=0.0142 R2=0.2365\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 37/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=424.3486 RMSE=0.0137 R2=0.2823 | Val Loss=2329.2456 RMSE=0.0140 R2=0.2554\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 38/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss=444.7784 RMSE=0.0140 R2=0.2477 | Val Loss=2322.1597 RMSE=0.0140 R2=0.2577\n",
      "No improvement in validation R^2 for 3 epochs.\n",
      "--- Epoch 39/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss=442.9476 RMSE=0.0140 R2=0.2508 | Val Loss=2306.8652 RMSE=0.0140 R2=0.2625\n",
      "No improvement in validation R^2 for 4 epochs.\n",
      "--- Epoch 40/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=463.1776 RMSE=0.0143 R2=0.2166 | Val Loss=2428.4136 RMSE=0.0143 R2=0.2237\n",
      "No improvement in validation R^2 for 5 epochs.\n",
      "--- Epoch 41/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss=449.8522 RMSE=0.0141 R2=0.2391 | Val Loss=2418.5312 RMSE=0.0143 R2=0.2269\n",
      "No improvement in validation R^2 for 6 epochs.\n",
      "--- Epoch 42/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss=411.7442 RMSE=0.0135 R2=0.3036 | Val Loss=2499.1460 RMSE=0.0145 R2=0.2011\n",
      "No improvement in validation R^2 for 7 epochs.\n",
      "--- Epoch 43/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss=399.8607 RMSE=0.0133 R2=0.3237 | Val Loss=2479.8770 RMSE=0.0145 R2=0.2072\n",
      "No improvement in validation R^2 for 8 epochs.\n",
      "--- Epoch 44/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss=410.2854 RMSE=0.0135 R2=0.3060 | Val Loss=2315.1528 RMSE=0.0140 R2=0.2599\n",
      "No improvement in validation R^2 for 9 epochs.\n",
      "--- Epoch 45/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss=414.6050 RMSE=0.0136 R2=0.2987 | Val Loss=2449.3984 RMSE=0.0144 R2=0.2170\n",
      "No improvement in validation R^2 for 10 epochs.\n",
      "--- Epoch 46/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss=407.1415 RMSE=0.0134 R2=0.3114 | Val Loss=2324.5986 RMSE=0.0140 R2=0.2569\n",
      "No improvement in validation R^2 for 11 epochs.\n",
      "--- Epoch 47/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss=418.0928 RMSE=0.0136 R2=0.2928 | Val Loss=2296.6802 RMSE=0.0139 R2=0.2658\n",
      "No improvement in validation R^2 for 12 epochs.\n",
      "--- Epoch 48/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss=408.4152 RMSE=0.0135 R2=0.3092 | Val Loss=2232.5806 RMSE=0.0137 R2=0.2863\n",
      "No improvement in validation R^2 for 13 epochs.\n",
      "--- Epoch 49/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss=435.4211 RMSE=0.0139 R2=0.2635 | Val Loss=2421.5137 RMSE=0.0143 R2=0.2259\n",
      "No improvement in validation R^2 for 14 epochs.\n",
      "--- Epoch 50/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss=410.9728 RMSE=0.0135 R2=0.3049 | Val Loss=2342.7922 RMSE=0.0141 R2=0.2511\n",
      "No improvement in validation R^2 for 15 epochs.\n",
      "--- Epoch 51/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss=396.1234 RMSE=0.0132 R2=0.3300 | Val Loss=2319.4458 RMSE=0.0140 R2=0.2585\n",
      "No improvement in validation R^2 for 16 epochs.\n",
      "--- Epoch 52/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss=408.7001 RMSE=0.0135 R2=0.3087 | Val Loss=2257.1326 RMSE=0.0138 R2=0.2784\n",
      "No improvement in validation R^2 for 17 epochs.\n",
      "--- Epoch 53/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss=404.9494 RMSE=0.0134 R2=0.3151 | Val Loss=2173.5132 RMSE=0.0135 R2=0.3052\n",
      "New best validation R^2: 0.3052\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 54/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss=401.8049 RMSE=0.0133 R2=0.3204 | Val Loss=2168.5771 RMSE=0.0135 R2=0.3068\n",
      "New best validation R^2: 0.3068\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 55/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss=405.4725 RMSE=0.0134 R2=0.3142 | Val Loss=2231.9050 RMSE=0.0137 R2=0.2865\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 56/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss=403.3150 RMSE=0.0134 R2=0.3178 | Val Loss=2223.2856 RMSE=0.0137 R2=0.2893\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 57/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss=400.8580 RMSE=0.0133 R2=0.3220 | Val Loss=2148.3550 RMSE=0.0135 R2=0.3132\n",
      "New best validation R^2: 0.3132\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 58/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss=409.2723 RMSE=0.0135 R2=0.3078 | Val Loss=2235.0488 RMSE=0.0137 R2=0.2855\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 59/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss=384.8003 RMSE=0.0131 R2=0.3491 | Val Loss=2198.5828 RMSE=0.0136 R2=0.2972\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 60/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss=389.9614 RMSE=0.0131 R2=0.3404 | Val Loss=2279.2603 RMSE=0.0139 R2=0.2714\n",
      "No improvement in validation R^2 for 3 epochs.\n",
      "--- Epoch 61/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Train Loss=372.8433 RMSE=0.0129 R2=0.3694 | Val Loss=2147.8916 RMSE=0.0135 R2=0.3134\n",
      "New best validation R^2: 0.3134\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 62/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Train Loss=395.7443 RMSE=0.0132 R2=0.3306 | Val Loss=2265.1760 RMSE=0.0138 R2=0.2759\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 63/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Train Loss=400.1942 RMSE=0.0133 R2=0.3231 | Val Loss=2058.2993 RMSE=0.0132 R2=0.3420\n",
      "New best validation R^2: 0.3420\n",
      "Saved new best model to /home/jupyter/MLC-Project/training_runs/NYC_UHINetCNN_20250430_022023/model_best.pth.tar\n",
      "--- Epoch 64/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Train Loss=398.6981 RMSE=0.0133 R2=0.3256 | Val Loss=2196.8345 RMSE=0.0136 R2=0.2977\n",
      "No improvement in validation R^2 for 1 epochs.\n",
      "--- Epoch 65/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Train Loss=398.6484 RMSE=0.0133 R2=0.3257 | Val Loss=2213.2070 RMSE=0.0137 R2=0.2925\n",
      "No improvement in validation R^2 for 2 epochs.\n",
      "--- Epoch 66/500 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Train Loss=405.5837 RMSE=0.0134 R2=0.3140 | Val Loss=2122.1089 RMSE=0.0134 R2=0.3216\n",
      "No improvement in validation R^2 for 3 epochs.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model {config['model_type']} initialized on {device}\") # Use config for model type\n",
    "\n",
    "# --- Optimizer and Loss ---\n",
    "# Initialize tracking variables for R^2 based checkpointing\n",
    "best_val_r2 = -float('inf') # Initialize best R^2 to negative infinity\n",
    "epochs_no_improve = 0\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "# Ensure loss functions are defined (typically in the previous cell)\n",
    "loss_fn = masked_mae_loss if config[\"loss_type\"] == \"mae\" else masked_mse_loss\n",
    "\n",
    "# --- Output Directory & Run Name ---\n",
    "run_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "run_name = f\"{config['wander_run_name_prefix']}_{run_timestamp}\"\n",
    "output_dir = Path(output_dir_base) / run_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "config[\"output_dir\"] = str(output_dir) # Update config with actual output dir\n",
    "print(f\"Checkpoints and logs will be saved to: {output_dir}\")\n",
    "\n",
    "# --- Retrieve UHI Stats ---\n",
    "# These should have been calculated and stored in config in Cell 5\n",
    "uhi_mean = config.get('uhi_mean')\n",
    "uhi_std = config.get('uhi_std')\n",
    "if uhi_mean is None or uhi_std is None:\n",
    "    raise ValueError(\"uhi_mean and uhi_std not found in config. Ensure they were calculated in the previous cell.\")\n",
    "print(f\"Using Training UHI Mean: {uhi_mean:.4f}, Std Dev: {uhi_std:.4f} for normalization.\")\n",
    "\n",
    "\n",
    "# --- Initialize WANDB ---\n",
    "# Ensure wandb is initialized if used\n",
    "if 'wandb' in sys.modules:\n",
    "    try:\n",
    "        # Finish any previous runs if necessary\n",
    "        if wandb.run is not None:\n",
    "            print(\"Finishing previous W&B run...\")\n",
    "            wandb.finish()\n",
    "\n",
    "        wandb.init(\n",
    "            project=config[\"wandb_project_name\"],\n",
    "            name=run_name,\n",
    "            config=config # Log the entire config dictionary\n",
    "        )\n",
    "        print(f\"Wandb initialized for run: {run_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Wandb initialization failed: {e}\")\n",
    "        wandb = None # Disable wandb logging if init fails\n",
    "else:\n",
    "    print(\"Wandb not imported, skipping W&B logging.\")\n",
    "    wandb = None\n",
    "\n",
    "# Save configuration used for this run locally as well\n",
    "try:\n",
    "    # Convert Path objects in config to strings for JSON serialization\n",
    "    config_serializable = {k: str(v) if isinstance(v, Path) else v for k, v in config.items()}\n",
    "    with open(output_dir / \"config.json\", 'w') as f:\n",
    "        json.dump(config_serializable, f, indent=2)\n",
    "    print(\"Saved local configuration to config.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Failed to save local configuration: {e}\")\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"Starting CNN training...\")\n",
    "training_log = [] # Local log\n",
    "last_saved_epoch = -1 # Track last saved epoch to avoid redundant saves\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    print(f\"--- Epoch {epoch+1}/{config['epochs']} ---\")\n",
    "\n",
    "    # --- Train Epoch ---\n",
    "    # Pass uhi_mean and uhi_std\n",
    "    train_loss, train_rmse, train_r2 = train_epoch(model, train_loader, optimizer, loss_fn, device,\n",
    "                                                   uhi_mean, uhi_std)\n",
    "\n",
    "    log_metrics = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"train_r2\": train_r2\n",
    "    }\n",
    "\n",
    "    # --- Validation and Checkpointing ---\n",
    "    is_best = False # Reset is_best flag each epoch\n",
    "    if val_loader:\n",
    "        # --- Validate Epoch ---\n",
    "        # Pass uhi_mean and uhi_std\n",
    "        val_loss, val_rmse, val_r2 = validate_epoch(model, val_loader, loss_fn, device,\n",
    "                                                    uhi_mean, uhi_std)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} RMSE={train_rmse:.4f} R2={train_r2:.4f} | Val Loss={val_loss:.4f} RMSE={val_rmse:.4f} R2={val_r2:.4f}\")\n",
    "        log_metrics.update({\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_rmse\": val_rmse,\n",
    "            \"val_r2\": val_r2\n",
    "        })\n",
    "\n",
    "        # Check improvement based on validation R^2\n",
    "        if np.isnan(val_r2):\n",
    "             print(\"Warning: Validation R^2 is NaN. Cannot determine improvement. Stopping training.\")\n",
    "             break # Stop training if validation R2 is NaN\n",
    "\n",
    "        is_best = val_r2 > best_val_r2\n",
    "\n",
    "        if is_best:\n",
    "            best_val_r2 = val_r2\n",
    "            epochs_no_improve = 0\n",
    "            print(f\"New best validation R^2: {best_val_r2:.4f}\")\n",
    "            if wandb:\n",
    "                wandb.run.summary[\"best_val_r2\"] = best_val_r2\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement in validation R^2 for {epochs_no_improve} epochs.\")\n",
    "\n",
    "        # Early stopping check (only if using validation)\n",
    "        if epochs_no_improve >= config[\"patience\"]:\n",
    "            print(f\"Early stopping triggered after {config['patience']} epochs with no improvement in validation R^2.\")\n",
    "            break\n",
    "\n",
    "    else: # No validation set\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} RMSE={train_rmse:.4f} R2={train_r2:.4f} (No validation set)\")\n",
    "        if np.isnan(train_loss):\n",
    "             print(\"Warning: Training loss is NaN. Stopping training.\")\n",
    "             break # Stop training if training loss is NaN\n",
    "\n",
    "    # --- Log Metrics ---\n",
    "    if wandb:\n",
    "        wandb.log(log_metrics)\n",
    "    training_log.append(log_metrics) # Also keep local log\n",
    "\n",
    "    # --- Save Checkpoint (Always save last, conditionally save best) ---\n",
    "    # Save the state from the *current* epoch\n",
    "    save_checkpoint(\n",
    "        {'epoch': epoch + 1, # Current epoch number\n",
    "         'state_dict': model.state_dict(),\n",
    "         'best_val_r2': best_val_r2, # Record the best R2 *seen so far*\n",
    "         'optimizer' : optimizer.state_dict(),\n",
    "         'config': config_serializable # Save the serializable config\n",
    "         },\n",
    "        is_best, # This flag determines if model_best.pth.tar is *overwritten*\n",
    "        filename=output_dir / 'checkpoint_last.pth.tar', # Always save the latest\n",
    "        best_filename=output_dir / 'model_best.pth.tar'  # Overwrite if current is best\n",
    "    )\n",
    "    if is_best:\n",
    "        last_saved_epoch = epoch + 1 # Update tracker\n",
    "\n",
    "\n",
    "# --- Final Steps ---\n",
    "# Save Local Training Log\n",
    "try:\n",
    "    log_df = pd.DataFrame(training_log)\n",
    "    log_df.to_csv(output_dir / 'training_log.csv', index=False)\n",
    "    print(f\"Saved local training log to {output_dir / 'training_log.csv'}\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Failed to save local training log: {e}\")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "if val_loader:\n",
    "    print(f\"Best validation R^2 recorded: {best_val_r2:.4f} (achieved at epoch {last_saved_epoch if last_saved_epoch > 0 else 'N/A'})\")\n",
    "print(f\"Final checkpoint saved in: {output_dir / 'checkpoint_last.pth.tar'}\")\n",
    "if last_saved_epoch > 0:\n",
    "     print(f\"Best model saved in: {output_dir / 'model_best.pth.tar'}\")\n",
    "\n",
    "# Finish WANDB run\n",
    "if wandb:\n",
    "    wandb.finish()\n",
    "    print(\"Wandb run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3405883-756d-4db5-9864-7e1852b45d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
