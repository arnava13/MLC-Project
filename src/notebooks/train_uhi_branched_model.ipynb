{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49488f02",
   "metadata": {},
   "source": [
    "# Branched UHI Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd353f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '/home/jupyter/MLC-Project']\n",
      "Project Root: /home/jupyter/MLC-Project\n",
      "PyTorch Version: 2.7.0+cu126\n",
      "CUDA Available: True\n",
      "CUDA Device Name: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "# %% Imports and Setup\n",
    "\n",
    "# --- Standard Libraries ---\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Data Handling ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray # For geospatial data handling with xarray\n",
    "\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset # Added Subset\n",
    "\n",
    "\n",
    "# --- Visualization & Progress ---\n",
    "# Optional: Import matplotlib or other plotting libs if needed for checks\n",
    "from tqdm.notebook import tqdm # Use notebook version if running interactively\n",
    "import wandb\n",
    "\n",
    "# --- Custom Modules ---\n",
    "# Project root is the parent directory of the current working directory\n",
    "project_root = Path(os.getcwd()).parent\n",
    "# project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path(os.getcwd()).parent\n",
    "src = project_root / \"src\"\n",
    "\n",
    "# Add src directory to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    print(sys.path)\n",
    "\n",
    "# Import custom modules\n",
    "from src.ingest.dataloader_branched import CityDataSetBranched\n",
    "from src.branched_uhi_model import BranchedUHIModel\n",
    "from src.train.loss import masked_mse_loss, masked_mae_loss # Import loss functions\n",
    "import src.train.train_utils as train_utils # Import the utility module\n",
    "\n",
    "# --- Environment Setup ---\n",
    "# Optional: Configure logging level\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Optional: Ignore specific warnings if needed\n",
    "# warnings.filterwarnings('ignore', category=UserWarning, message='.*TypedStorage is deprecated.*')\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3212078d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded bounds from uhi.csv: [np.float64(-73.99445667), np.float64(40.75879167), np.float64(-73.87945833), np.float64(40.85949667)]\n",
      "Run directory: /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717\n",
      "\\nBranched Model Configuration dictionary created:\n",
      "{\n",
      "  \"model_type\": \"BranchedUHIModel\",\n",
      "  \"project_root\": \"/home/jupyter/MLC-Project\",\n",
      "  \"city_name\": \"NYC\",\n",
      "  \"wandb_project_name\": \"MLC_UHI_Proj\",\n",
      "  \"wander_run_name_prefix\": \"NYC_BranchedUHI\",\n",
      "  \"feature_resolution_m\": 50,\n",
      "  \"uhi_grid_resolution_m\": 50,\n",
      "  \"temporal_seq_len\": 60,\n",
      "  \"clay_proj_channels\": 16,\n",
      "  \"enabled_weather_features\": [\n",
      "    \"air_temp\",\n",
      "    \"rel_humidity\",\n",
      "    \"avg_windspeed\",\n",
      "    \"wind_direction\",\n",
      "    \"solar_flux\"\n",
      "  ],\n",
      "  \"uhi_csv\": \"/home/jupyter/MLC-Project/data/NYC/uhi.csv\",\n",
      "  \"bronx_weather_csv\": \"/home/jupyter/MLC-Project/data/NYC/bronx_weather.csv\",\n",
      "  \"manhattan_weather_csv\": \"/home/jupyter/MLC-Project/data/NYC/manhattan_weather.csv\",\n",
      "  \"bounds\": [\n",
      "    -73.99445667,\n",
      "    40.75879167,\n",
      "    -73.87945833,\n",
      "    40.85949667\n",
      "  ],\n",
      "  \"feature_flags\": {\n",
      "    \"use_dem\": false,\n",
      "    \"use_dsm\": true,\n",
      "    \"use_clay\": true,\n",
      "    \"use_sentinel_composite\": false,\n",
      "    \"use_lst\": false,\n",
      "    \"use_ndvi\": false,\n",
      "    \"use_ndbi\": false,\n",
      "    \"use_ndwi\": false\n",
      "  },\n",
      "  \"sentinel_bands_to_load\": [],\n",
      "  \"dem_path\": null,\n",
      "  \"dsm_path\": \"/home/jupyter/MLC-Project/data/NYC/sat_files/nyc_dsm_cop-dem-glo-30_native-resolution_pc.tif\",\n",
      "  \"elevation_nodata\": NaN,\n",
      "  \"cloudless_mosaic_path\": \"/home/jupyter/MLC-Project/data/NYC/sat_files/sentinel_NYC_20210601_to_20210901_cloudless_mosaic.npy\",\n",
      "  \"single_lst_median_path\": null,\n",
      "  \"lst_nodata\": NaN,\n",
      "  \"convlstm_hidden_dims\": [\n",
      "    32,\n",
      "    16\n",
      "  ],\n",
      "  \"convlstm_kernel_sizes\": [\n",
      "    [\n",
      "      3,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      3\n",
      "    ]\n",
      "  ],\n",
      "  \"convlstm_num_layers\": 2,\n",
      "  \"proj_static_ch\": 2,\n",
      "  \"proj_temporal_ch\": 16,\n",
      "  \"head_type\": \"unet\",\n",
      "  \"unet_base_channels\": 32,\n",
      "  \"unet_depth\": 3,\n",
      "  \"unet_dropout_rate\": 0.3,\n",
      "  \"simple_cnn_hidden_dims\": null,\n",
      "  \"simple_cnn_kernel_size\": null,\n",
      "  \"simple_cnn_dropout_rate\": null,\n",
      "  \"clay_model_size\": \"large\",\n",
      "  \"clay_bands\": [\n",
      "    \"blue\",\n",
      "    \"green\",\n",
      "    \"red\",\n",
      "    \"nir\"\n",
      "  ],\n",
      "  \"clay_platform\": \"sentinel-2-l2a\",\n",
      "  \"clay_gsd\": 10,\n",
      "  \"freeze_backbone\": true,\n",
      "  \"clay_checkpoint_path\": \"/home/jupyter/MLC-Project/notebooks/clay-v1.5.ckpt\",\n",
      "  \"clay_metadata_path\": \"/home/jupyter/MLC-Project/src/Clay/configs/metadata.yaml\",\n",
      "  \"n_train_batches\": 12,\n",
      "  \"num_workers\": 1,\n",
      "  \"epochs\": 500,\n",
      "  \"lr\": 5e-05,\n",
      "  \"weight_decay\": 0.0005,\n",
      "  \"loss_type\": \"mse\",\n",
      "  \"patience\": 50,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"device\": \"cuda\",\n",
      "  \"run_dir\": \"/home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# %% Configuration / Hyperparameters for BranchedUHIModel (ConvLSTM + Common Resampling)\n",
    "\n",
    "# --- Import utils ---\n",
    "from src.train.train_utils import check_path # For path validation\n",
    "from src.ingest.data_utils import calculate_actual_weather_channels # For dynamic weather channels\n",
    "# -------------------\n",
    "\n",
    "# --- Paths & Basic Info ---\n",
    "# project_root is defined in the first cell\n",
    "project_root_str = str(project_root)\n",
    "data_dir = project_root / \"data\"\n",
    "city_name = \"NYC\" # Should be defined or loaded\n",
    "output_dir_base = project_root / \"training_runs\"\n",
    "\n",
    "# --- WANDB Config ---\n",
    "wandb_project_name = \"MLC_UHI_Proj\"\n",
    "wander_run_name_prefix = f\"{city_name}_BranchedUHI\"\n",
    "\n",
    "# --- Data Loading Config ---\n",
    "feature_resolution_m = 50\n",
    "uhi_grid_resolution_m = 50 # UHI target grid\n",
    "temporal_seq_len = 60 \n",
    "\n",
    "# --- Weather Feature Selection\n",
    "enabled_weather_features = [\n",
    "    \"air_temp\", \n",
    "    \"rel_humidity\", \n",
    "    \"avg_windspeed\", \n",
    "    \"wind_direction\",      \n",
    "    \"solar_flux\"\n",
    "]\n",
    "# Calculate the number of actual weather channels that will be produced by the dataloader\n",
    "actual_dataloader_weather_channels = calculate_actual_weather_channels(enabled_weather_features)\n",
    "# ------------------------------------\n",
    "\n",
    "# --- Define Absolute Input Data Paths Directly ---\n",
    "uhi_csv_path = data_dir / city_name / \"uhi.csv\"\n",
    "bronx_weather_csv_path = data_dir / city_name / \"bronx_weather.csv\"\n",
    "manhattan_weather_csv_path = data_dir / city_name / \"manhattan_weather.csv\"\n",
    "\n",
    "dem_path = data_dir / city_name / \"sat_files\" / f\"{city_name.lower()}_dem_nasadem_native-resolution_pc.tif\"\n",
    "dsm_path = data_dir / city_name / \"sat_files\" / f\"{city_name.lower()}_dsm_cop-dem-glo-30_native-resolution_pc.tif\"\n",
    "cloudless_mosaic_path = data_dir / city_name / \"sat_files\" / f\"sentinel_{city_name}_20210601_to_20210901_cloudless_mosaic.npy\" # Added .npy\n",
    "# Assuming the LST filename structure from download_data.ipynb if it's used\n",
    "lst_time_window_str_for_filename = \"20210601_to_20210901\" # Match download_data\n",
    "single_lst_median_path = data_dir / city_name / \"sat_files\" / f\"lst_{city_name}_median_{lst_time_window_str_for_filename}.npy\" # Corrected and added .npy\n",
    "\n",
    "\n",
    "# Nodata values\n",
    "elevation_nodata = np.nan # Or np.nan\n",
    "lst_nodata = np.nan # Or np.nan\n",
    "\n",
    "# --- Feature Selection Flags ---\n",
    "feature_flags = {\n",
    "    \"use_dem\": False,\n",
    "    \"use_dsm\": True,\n",
    "    \"use_clay\": True,\n",
    "    \"use_sentinel_composite\": False,\n",
    "    \"use_lst\": False, # Set to True if LST is intended to be used\n",
    "    \"use_ndvi\": False,\n",
    "    \"use_ndbi\": False,\n",
    "    \"use_ndwi\": False,\n",
    "}\n",
    "\n",
    "# --- Bands for Sentinel Composite (if use_sentinel_composite is True) ---\n",
    "sentinel_bands_to_load = []\n",
    "\n",
    "# --- Model Config (BranchedUHIModel with ConvLSTM, No separate Elev branches) ---\n",
    "# Clay Backbone\n",
    "clay_model_size = \"large\"\n",
    "clay_bands = [\"blue\", \"green\", \"red\", \"nir\"]\n",
    "clay_platform = \"sentinel-2-l2a\"\n",
    "clay_gsd = 10\n",
    "freeze_backbone = True # Keep Clay backbone frozen for BranchedUHIModel typically\n",
    "clay_checkpoint_path = project_root / \"notebooks\" / \"clay-v1.5.ckpt\"\n",
    "clay_metadata_path = project_root / \"src\" / \"Clay\" / \"configs\" / \"metadata.yaml\"\n",
    "\n",
    "# Temporal Weather Processor (ConvLSTM)\n",
    "convlstm_hidden_dims = [32, 16] # Keeping original depth for now\n",
    "convlstm_kernel_sizes = [(3,3), (3,3)]\n",
    "convlstm_num_layers = len(convlstm_hidden_dims)\n",
    "\n",
    "# Projection Layer Channels\n",
    "clay_proj_channels = 16\n",
    "proj_static_ch = 2 \n",
    "proj_temporal_ch = 16\n",
    "projection_dropout_rate = 0.1 # ADDED\n",
    "\n",
    "# --- Head Configuration ---\n",
    "head_type = \"unet\" # Options: \"unet\" or \"simple_cnn\"\n",
    "# U-Net specific\n",
    "unet_base_channels = 32\n",
    "unet_depth = 3 # Keeping original depth for now\n",
    "unet_dropout_rate = 0.3 # Dropout for U-Net blocks\n",
    "# SimpleCNN specific\n",
    "simple_cnn_hidden_dims = [32, 16] # Example, adjust as needed\n",
    "simple_cnn_kernel_size = 3\n",
    "simple_cnn_dropout_rate = 0.1 # Dropout for SimpleCNN Head\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "num_workers = 1\n",
    "epochs = 500\n",
    "lr = 5e-5 # From previous successful run\n",
    "weight_decay = 5e-4 # From previous successful run\n",
    "loss_type = 'mse'\n",
    "patience = 50 # Early stopping patience\n",
    "reduce_lr_patience = 20 # Patience for ReduceLROnPlateau scheduler\n",
    "cpu = False\n",
    "max_grad_norm = 1.0\n",
    "# Effective batch size will be num_train_samples // n_train_batches\n",
    "# Assuming 47 training samples from logs: 47 // 11 batches -> avg batch size ~4.27, actual is 4 for most, last one smaller or 3 if 47//12\n",
    "n_train_batches = 11 # For batch size ~4 with 47 training samples (47//11 = 4)\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not cpu else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Validate Paths (using check_path for files that *must* exist) ---\n",
    "uhi_csv_path = check_path(uhi_csv_path, project_root, \"UHI CSV\")\n",
    "bronx_weather_csv_path = check_path(bronx_weather_csv_path, project_root, \"Bronx Weather CSV\")\n",
    "manhattan_weather_csv_path = check_path(manhattan_weather_csv_path, project_root, \"Manhattan Weather CSV\")\n",
    "\n",
    "if feature_flags[\"use_dem\"]:\n",
    "    dem_path = check_path(dem_path, project_root, \"DEM TIF\")\n",
    "if feature_flags[\"use_dsm\"]:\n",
    "    dsm_path = check_path(dsm_path, project_root, \"DSM TIF\")\n",
    "if feature_flags[\"use_clay\"]:\n",
    "    clay_checkpoint_path = check_path(clay_checkpoint_path, project_root, \"Clay Checkpoint\")\n",
    "    clay_metadata_path = check_path(clay_metadata_path, project_root, \"Clay Metadata\")\n",
    "if feature_flags[\"use_clay\"] or feature_flags[\"use_sentinel_composite\"]:\n",
    "    cloudless_mosaic_path = check_path(cloudless_mosaic_path, project_root, \"Cloudless Mosaic\")\n",
    "if feature_flags[\"use_lst\"]:\n",
    "    single_lst_median_path = check_path(single_lst_median_path, project_root, \"Single LST Median\", should_exist=True)\n",
    "\n",
    "\n",
    "# --- Calculate Bounds ---\n",
    "uhi_df = pd.read_csv(uhi_csv_path) \n",
    "required_cols = ['Longitude', 'Latitude']\n",
    "if not all(col in uhi_df.columns for col in required_cols):\n",
    "    raise ValueError(f\"UHI CSV must contain columns: {required_cols}\")\n",
    "bounds = [\n",
    "    uhi_df['Longitude'].min(),\n",
    "    uhi_df['Latitude'].min(),\n",
    "    uhi_df['Longitude'].max(),\n",
    "    uhi_df['Latitude'].max()\n",
    "]\n",
    "print(f\"Loaded bounds from {uhi_csv_path.name}: {bounds}\") \n",
    "\n",
    "\n",
    "# --- Central Config Dictionary --- #\n",
    "config = {\n",
    "    # Paths & Info\n",
    "    \"model_type\": \"BranchedUHIModel\", \n",
    "    \"project_root\": project_root_str,\n",
    "    \"city_name\": city_name,\n",
    "    \"wandb_project_name\": wandb_project_name,\n",
    "    \"wander_run_name_prefix\": wander_run_name_prefix,\n",
    "    # Data Loading\n",
    "    \"feature_resolution_m\": feature_resolution_m,\n",
    "    \"uhi_grid_resolution_m\": uhi_grid_resolution_m,\n",
    "    \"temporal_seq_len\": temporal_seq_len,\n",
    "    \"clay_proj_channels\": clay_proj_channels,\n",
    "    \"enabled_weather_features\": enabled_weather_features, \n",
    "    \"uhi_csv\": str(uhi_csv_path),\n",
    "    \"bronx_weather_csv\": str(bronx_weather_csv_path),\n",
    "    \"manhattan_weather_csv\": str(manhattan_weather_csv_path),\n",
    "    \"bounds\": bounds,\n",
    "    \"feature_flags\": feature_flags,\n",
    "    \"sentinel_bands_to_load\": sentinel_bands_to_load,\n",
    "    \"dem_path\": str(dem_path) if feature_flags[\"use_dem\"] else None,\n",
    "    \"dsm_path\": str(dsm_path) if feature_flags[\"use_dsm\"] else None,\n",
    "    \"elevation_nodata\": elevation_nodata,\n",
    "    \"cloudless_mosaic_path\": str(cloudless_mosaic_path) if feature_flags[\"use_clay\"] or feature_flags[\"use_sentinel_composite\"] else None,\n",
    "    \"single_lst_median_path\": str(single_lst_median_path) if feature_flags[\"use_lst\"] else None,\n",
    "    \"lst_nodata\": lst_nodata,\n",
    "    # Model Config\n",
    "    \"convlstm_hidden_dims\": convlstm_hidden_dims,\n",
    "    \"convlstm_kernel_sizes\": convlstm_kernel_sizes,\n",
    "    \"convlstm_num_layers\": convlstm_num_layers,\n",
    "    \"proj_static_ch\": proj_static_ch,\n",
    "    \"proj_temporal_ch\": proj_temporal_ch,\n",
    "    \"projection_dropout_rate\": projection_dropout_rate, # ADDED\n",
    "    \"head_type\": head_type,\n",
    "    \"unet_base_channels\": unet_base_channels if head_type == \"unet\" else None,\n",
    "    \"unet_depth\": unet_depth if head_type == \"unet\" else None,\n",
    "    \"unet_dropout_rate\": unet_dropout_rate if head_type == \"unet\" else None,\n",
    "    \"simple_cnn_hidden_dims\": simple_cnn_hidden_dims if head_type == \"simple_cnn\" else None,\n",
    "    \"simple_cnn_kernel_size\": simple_cnn_kernel_size if head_type == \"simple_cnn\" else None,\n",
    "    \"simple_cnn_dropout_rate\": simple_cnn_dropout_rate if head_type == \"simple_cnn\" else None,\n",
    "    # Clay specific\n",
    "    \"clay_model_size\": clay_model_size,\n",
    "    \"clay_bands\": clay_bands,\n",
    "    \"clay_platform\": clay_platform,\n",
    "    \"clay_gsd\": clay_gsd,\n",
    "    \"freeze_backbone\": freeze_backbone,\n",
    "    \"clay_checkpoint_path\": str(clay_checkpoint_path) if feature_flags[\"use_clay\"] else None,\n",
    "    \"clay_metadata_path\": str(clay_metadata_path) if feature_flags[\"use_clay\"] else None,\n",
    "    # Training Hyperparameters\n",
    "    \"n_train_batches\": n_train_batches,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"loss_type\": loss_type,\n",
    "    \"patience\": patience, # For EarlyStopping\n",
    "    \"reduce_lr_patience\": reduce_lr_patience, # For ReduceLROnPlateau\n",
    "    \"max_grad_norm\": max_grad_norm,\n",
    "    \"device\": str(device)\n",
    "}\n",
    "\n",
    "# --- Create Run Directory & Update Config ---\n",
    "run_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "run_name_suffix = f\"{config['model_type']}_{city_name}_{config['head_type']}_{run_timestamp}\"\n",
    "run_dir = output_dir_base / run_name_suffix\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "config[\"run_dir\"] = str(run_dir) \n",
    "\n",
    "print(f\"Run directory: {run_dir}\")\n",
    "print(\"\\\\nBranched Model Configuration dictionary created:\")\n",
    "print(json.dumps(config, indent=2, default=lambda x: str(x) if isinstance(x, (Path, torch.device)) else x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b31ff2-f0b1-4823-93c1-b62dfb77abc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 17:27:17,797 - INFO - Dataloader configured to include previous UHI grid for autoregression (always active).\n",
      "2025-05-07 17:27:17,798 - INFO - Dataloader will produce 6 weather channels based on enabled features: ['air_temp', 'rel_humidity', 'avg_windspeed', 'wind_direction', 'solar_flux']\n",
      "2025-05-07 17:27:17,799 - INFO - Target FEATURE grid size (H, W): (224, 194) @ 50m, CRS: EPSG:4326\n",
      "2025-05-07 17:27:17,799 - INFO - Target UHI grid size (H, W): (224, 194) @ 50m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BranchedCityDataSet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing UHI grids: 100%|██████████| 59/59 [00:00<00:00, 3704.05it/s]\n",
      "2025-05-07 17:27:17,854 - INFO - Loading DSM from: /home/jupyter/MLC-Project/data/NYC/sat_files/nyc_dsm_cop-dem-glo-30_native-resolution_pc.tif\n",
      "2025-05-07 17:27:17,866 - INFO - DSM loaded raw shape: (1, 364, 415)\n",
      "2025-05-07 17:27:17,878 - INFO - Clipping DSM to bounds: [np.float64(-73.99445667), np.float64(40.75879167), np.float64(-73.87945833), np.float64(40.85949667)]\n",
      "2025-05-07 17:27:17,879 - INFO - Opened DSM (lazy load). Native shape (approx): (1, 364, 415)\n",
      "2025-05-07 17:27:17,880 - INFO - Calculating global DSM 2nd/98th percentiles...\n",
      "2025-05-07 17:27:17,885 - INFO - Global DSM p2: 0.00, p98: 94.01\n",
      "2025-05-07 17:27:17,886 - INFO - Loading cloudless mosaic from /home/jupyter/MLC-Project/data/NYC/sat_files/sentinel_NYC_20210601_to_20210901_cloudless_mosaic.npy with memory mapping\n",
      "2025-05-07 17:27:17,887 - INFO - Loaded mosaic shape (native res): (5, 1119, 1278)\n",
      "2025-05-07 17:27:17,895 - INFO - Loaded Bronx weather data: 169 records\n",
      "2025-05-07 17:27:17,896 - INFO - Loaded Manhattan weather data: 169 records\n",
      "2025-05-07 17:27:17,897 - INFO - Computed grid cell center coordinates for CRS: EPSG:4326.\n",
      "2025-05-07 17:27:17,898 - INFO - Computed grid cell center coordinates for potential weather grid building at feature resolution.\n",
      "2025-05-07 17:27:17,899 - INFO - Dataset initialized for NYC with 59 unique timestamps.\n",
      "2025-05-07 17:27:17,899 - INFO - Temporal sequence length T = 60\n",
      "2025-05-07 17:27:17,899 - INFO - Enabled features (flags): {\"use_dem\": false, \"use_dsm\": true, \"use_clay\": true, \"use_sentinel_composite\": false, \"use_lst\": false, \"use_ndvi\": false, \"use_ndbi\": false, \"use_ndwi\": false}\n",
      "2025-05-07 17:27:17,900 - INFO - DEM loaded: False\n",
      "2025-05-07 17:27:17,900 - INFO - DSM loaded: True\n",
      "2025-05-07 17:27:17,901 - INFO - LST loaded: False\n",
      "2025-05-07 17:27:17,901 - INFO - Mosaic loaded: True\n",
      "2025-05-07 17:27:17,902 - INFO - Calculating UHI statistics from training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential dataset split: 47 training (indices 0-46), 12 validation (indices 47-58) samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating stats: 100%|██████████| 47/47 [00:00<00:00, 9596.55it/s]\n",
      "2025-05-07 17:27:17,911 - INFO - Training UHI Mean: 1.0004, Std Dev: 0.0169\n",
      "2025-05-07 17:27:17,912 - INFO - Creating dataloaders...\n",
      "2025-05-07 17:27:17,913 - INFO - Using Train Batch Size: 3\n",
      "2025-05-07 17:27:17,915 - INFO - Using Validation Batch Size: 1\n",
      "2025-05-07 17:27:17,915 - INFO - Data loading setup complete.\n"
     ]
    }
   ],
   "source": [
    "\\\n",
    "# %% Data Loading and Preprocessing (Branched Model + Common Resampling)\n",
    "\n",
    "# --- Import utils ---\n",
    "from src.train.train_utils import (\n",
    "    calculate_uhi_stats, # Removed split_data\n",
    "    create_dataloaders\n",
    ")\n",
    "from torch.utils.data import Subset # Import Subset\n",
    "# -------------------\n",
    "\n",
    "print(\"Initializing BranchedCityDataSet...\")\n",
    "try:\n",
    "    dataset = CityDataSetBranched(\n",
    "        bounds=config[\"bounds\"],\n",
    "        feature_resolution_m=config[\"feature_resolution_m\"], # Corrected param name\n",
    "        uhi_grid_resolution_m=config[\"uhi_grid_resolution_m\"], # Corrected param name\n",
    "        uhi_csv=config[\"uhi_csv\"], # Use paths from config\n",
    "        bronx_weather_csv=config[\"bronx_weather_csv\"],\n",
    "        manhattan_weather_csv=config[\"manhattan_weather_csv\"],\n",
    "        data_dir=project_root_str,\n",
    "        city_name=config[\"city_name\"],\n",
    "        feature_flags=config[\"feature_flags\"],\n",
    "        enabled_weather_features=config[\"enabled_weather_features\"], # NEW: Pass from config\n",
    "        sentinel_bands_to_load=config[\"sentinel_bands_to_load\"],\n",
    "        dem_path=config[\"dem_path\"], # Corrected param name\n",
    "        dsm_path=config[\"dsm_path\"], # Corrected param name\n",
    "        elevation_nodata=config[\"elevation_nodata\"], # Corrected param name\n",
    "        cloudless_mosaic_path=config[\"cloudless_mosaic_path\"],\n",
    "        single_lst_median_path=config[\"single_lst_median_path\"],\n",
    "        lst_nodata=config[\"lst_nodata\"], # Added missing param\n",
    "        temporal_seq_len=config[\"temporal_seq_len\"], # RENAMED from weather_seq_length\n",
    "        target_crs_str=config.get(\"target_crs_str\", \"EPSG:4326\") # Added optional param\n",
    "        # use_autoregressive_uhi is removed here as it's always active in the dataloader now\n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Dataset initialization failed: {e}\")\n",
    "    print(\"Ensure required data files (DEM, DSM, weather, UHI, potentially mosaic/LST) exist.\")\n",
    "    print(\"Run `notebooks/download_data.ipynb` first.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error during dataset initialization: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Sequential Train/Val Split --- #\n",
    "val_percent = 0.20 # Keep the percentage definition\n",
    "num_samples = len(dataset)\n",
    "if num_samples < 2: # Need at least one for train and one for val\n",
    "    raise ValueError(f\"Dataset has only {num_samples} samples, cannot perform train/val split.\")\n",
    "\n",
    "n_train = int(num_samples * (1 - val_percent))\n",
    "n_val = num_samples - n_train\n",
    "\n",
    "if n_train == 0 or n_val == 0:\n",
    "    raise ValueError(f\"Split resulted in zero samples for train ({n_train}) or validation ({n_val}). Adjust val_percent or check dataset size.\")\n",
    "\n",
    "train_indices = list(range(n_train))\n",
    "val_indices = list(range(n_train, num_samples))\n",
    "\n",
    "train_ds = Subset(dataset, train_indices)\n",
    "val_ds = Subset(dataset, val_indices)\n",
    "\n",
    "print(f\"Sequential dataset split: {len(train_ds)} training (indices 0-{n_train-1}), {len(val_ds)} validation (indices {n_train}-{num_samples-1}) samples.\")\n",
    "\n",
    "# --- Calculate UHI Mean and Std from Training Data ONLY --- #\n",
    "uhi_mean, uhi_std = calculate_uhi_stats(train_ds)\n",
    "config['uhi_mean'] = uhi_mean\n",
    "config['uhi_std'] = uhi_std\n",
    "\n",
    "# --- Create DataLoaders --- #\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_ds,\n",
    "    val_ds,\n",
    "    n_train_batches=config['n_train_batches'],\n",
    "    num_workers=config['num_workers'],\n",
    "    device=device # Pass device from config cell\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e90e15-1b5c-46f7-aedf-b3fe60662f67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 17:27:17,928 - INFO - BranchedModel configured for target output UHI grid: (224, 194)\n",
      "2025-05-07 17:27:17,939 - INFO - ConvLSTM input dimension set to 7 (Weather: 6 + Prev UHI: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BranchedUHIModel...\n",
      "Manually loading checkpoint: /home/jupyter/MLC-Project/notebooks/clay-v1.5.ckpt\n",
      "Instantiating ClayMAEModule manually...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 17:27:25,129 - INFO - Loading pretrained weights from Hugging Face hub (timm/vit_large_patch14_reg4_dinov2.lvd142m)\n",
      "2025-05-07 17:27:25,247 - INFO - [timm/vit_large_patch14_reg4_dinov2.lvd142m] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading state_dict manually into self.model.model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 17:27:28,978 - INFO - Identified final encoder layer as self.model.model.proj\n",
      "2025-05-07 17:27:28,979 - INFO - Keeping Clay backbone frozen.\n",
      "2025-05-07 17:27:28,984 - INFO - ClayFeatureExtractor output channels set to: 1024\n",
      "2025-05-07 17:27:29,052 - INFO - Added BatchNorm2d before Clay projection for 1024 channels\n",
      "2025-05-07 17:27:29,054 - INFO - Added Clay projection Conv1x1: 1024 -> 16 channels\n",
      "2025-05-07 17:27:29,055 - INFO - Total input channels for STATIC projection: 1\n",
      "2025-05-07 17:27:29,055 - INFO - ConvLSTM input channels (actual_weather_input_channels): 6\n",
      "2025-05-07 17:27:29,056 - INFO - Static projection: 1 -> 2 channels\n",
      "2025-05-07 17:27:29,057 - INFO - Temporal projection: 16 -> 16 channels\n",
      "2025-05-07 17:27:29,058 - INFO - Adding clay_output_channels (16) to head input channels\n",
      "2025-05-07 17:27:29,071 - INFO - Initialized UNetDecoder. In channels: 34, Base channels: 32, Depth: 3\n",
      "2025-05-07 17:27:29,072 - INFO - BranchedModel using UNetDecoder head. Output channels: 32\n",
      "2025-05-07 17:27:29,073 - INFO - Initialized FinalUpsamplerAndProjection: Bicubic upsampling. InCh=32, Target=(224,194).\n",
      "2025-05-07 17:27:29,073 - INFO - BranchedUHIModel initialized with unet head and FinalUpsamplerAndProjection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Overriding patch size from hparams. Using fixed patch_size = 16\n",
      "Clay model properties: model_size=large, embed_dim=1024, patch_size=16 (patch_size OVERRIDDEN)\n",
      "Normalization prepared for bands: ['blue', 'green', 'red', 'nir']\n",
      "BranchedUHIModel initialized successfully.\n",
      "Optimizer (AdamW) initialized.\n",
      "Loss function set to masked_mse_loss.\n",
      "Initialized ReduceLROnPlateau scheduler.\n",
      "\\nModel, optimizer, loss function, and scheduler setup complete.\n"
     ]
    }
   ],
   "source": [
    "\\\n",
    "# %% Model Initialization (Branched Model + Common Resampling)\n",
    "\n",
    "# --- Import necessary components ---\n",
    "from src.branched_uhi_model import BranchedUHIModel\n",
    "from src.train.loss import masked_mse_loss, masked_mae_loss\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import logging # Ensure logging is imported if not already\n",
    "\n",
    "# Instantiate the BranchedUHIModel\n",
    "print(f\"Initializing {config['model_type']}...\")\n",
    "try:\n",
    "    model = BranchedUHIModel(\n",
    "        # --- Weather Branch Config --- #\n",
    "        enabled_weather_features=config[\"enabled_weather_features\"], \n",
    "        convlstm_hidden_dims=config[\"convlstm_hidden_dims\"],\n",
    "        convlstm_kernel_sizes=config[\"convlstm_kernel_sizes\"],\n",
    "        convlstm_num_layers=config[\"convlstm_num_layers\"],\n",
    "        temporal_seq_len=config[\"temporal_seq_len\"],\n",
    "        # --- Static Feature Config --- #\n",
    "        feature_flags=config[\"feature_flags\"],\n",
    "        clay_proj_channels=config[\"clay_proj_channels\"],\n",
    "        sentinel_bands_to_load=config.get(\"sentinel_bands_to_load\"), \n",
    "        # Clay Specific\n",
    "        clay_model_size=config.get(\"clay_model_size\"),\n",
    "        clay_bands=config.get(\"clay_bands\"),\n",
    "        clay_platform=config.get(\"clay_platform\"),\n",
    "        clay_gsd=config.get(\"clay_gsd\"),\n",
    "        freeze_backbone=config.get(\"freeze_backbone\", True),\n",
    "        clay_checkpoint_path=config.get(\"clay_checkpoint_path\"),\n",
    "        clay_metadata_path=config.get(\"clay_metadata_path\"),\n",
    "        # --- Projection Config --- #\n",
    "        proj_static_ch=config[\"proj_static_ch\"],\n",
    "        proj_temporal_ch=config[\"proj_temporal_ch\"],\n",
    "        projection_dropout_rate=config.get(\"projection_dropout_rate\", 0.0), # ADDED\n",
    "        # --- Head Config --- #\n",
    "        head_type=config[\"head_type\"],\n",
    "        unet_base_channels=config.get(\"unet_base_channels\"), \n",
    "        unet_depth=config.get(\"unet_depth\"),\n",
    "        unet_dropout_rate=config.get(\"unet_dropout_rate\"),\n",
    "        simple_cnn_hidden_dims=config.get(\"simple_cnn_hidden_dims\"),\n",
    "        simple_cnn_kernel_size=config.get(\"simple_cnn_kernel_size\"),\n",
    "        simple_cnn_dropout_rate=config.get(\"simple_cnn_dropout_rate\", 0.1), \n",
    "        # --- Target Grid Info --- #\n",
    "        uhi_grid_resolution_m=config[\"uhi_grid_resolution_m\"],\n",
    "        bounds=config[\"bounds\"]\n",
    "    )\n",
    "    model.to(config[\"device\"])\n",
    "    print(f\"{config['model_type']} initialized successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing BranchedUHIModel: {e}\", exc_info=True)\n",
    "    raise # Re-raise the exception after logging\n",
    "\n",
    "# --- Optimizer --- #\n",
    "try:\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    print(\"Optimizer (AdamW) initialized.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing optimizer: {e}\", exc_info=True)\n",
    "    raise\n",
    "\n",
    "# --- Loss Function --- #\n",
    "if config[\"loss_type\"] == 'mse':\n",
    "    loss_fn = masked_mse_loss\n",
    "    print(\"Loss function set to masked_mse_loss.\")\n",
    "elif config[\"loss_type\"] == 'mae':\n",
    "    loss_fn = masked_mae_loss\n",
    "    print(\"Loss function set to masked_mae_loss.\")\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported loss type: {config['loss_type']}\")\n",
    "\n",
    "# --- LR Scheduler --- #\n",
    "try:\n",
    "    # Use the specific patience for the LR scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=config['reduce_lr_patience'], factor=0.5)\n",
    "    print(f\"Initialized ReduceLROnPlateau scheduler with patience={config['reduce_lr_patience']}.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing scheduler: {e}\", exc_info=True)\n",
    "    scheduler = None \n",
    "    print(\"Proceeding without LR scheduler due to initialization error.\")\n",
    "\n",
    "\n",
    "print(\"\\\\nModel, optimizer, loss function, and scheduler setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1b761f-1d71-4581-bf50-c785d8e88a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights & Biases (wandb) available for logging.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnava1304\u001b[0m (\u001b[33marnava1304-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/MLC-Project/notebooks/wandb/run-20250507_172729-w8xg7pex</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/w8xg7pex' target=\"_blank\">NYC_BranchedUHI_20250507_1727</a></strong> to <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj' target=\"_blank\">https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/w8xg7pex' target=\"_blank\">https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/w8xg7pex</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 500 epochs with patience 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0722, Train RMSE: 0.0176, Train R2: -0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.7241, Val RMSE:   0.0144, Val R2:   -0.0276\n",
      "Warmup epoch 1/5. Skipping checkpointing and early stopping.\n",
      "Epoch 1/500 completed in 51.86s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9987, Train RMSE: 0.0169, Train R2: -0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.7100, Val RMSE:   0.0142, Val R2:   -0.0067\n",
      "Warmup epoch 2/5. Skipping checkpointing and early stopping.\n",
      "Epoch 2/500 completed in 50.57s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9760, Train RMSE: 0.0169, Train R2: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6941, Val RMSE:   0.0140, Val R2:   0.0199\n",
      "Warmup epoch 3/5. Skipping checkpointing and early stopping.\n",
      "Epoch 3/500 completed in 50.79s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0049, Train RMSE: 0.0170, Train R2: -0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6675, Val RMSE:   0.0137, Val R2:   0.0607\n",
      "Warmup epoch 4/5. Skipping checkpointing and early stopping.\n",
      "Epoch 4/500 completed in 50.81s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9637, Train RMSE: 0.0165, Train R2: 0.0458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6554, Val RMSE:   0.0136, Val R2:   0.0739\n",
      "Warmup epoch 5/5. Skipping checkpointing and early stopping.\n",
      "Epoch 5/500 completed in 50.53s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9776, Train RMSE: 0.0166, Train R2: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6663, Val RMSE:   0.0138, Val R2:   0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 17:32:46,487 - INFO - Saved current checkpoint to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/checkpoints/checkpoint.pth.tar\n",
      "2025-05-07 17:32:48,347 - INFO - Saved new best model to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/checkpoints/model_best.pth.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 6 with val_loss 0.6663\n",
      "Epoch 6/500 completed in 63.18s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9241, Train RMSE: 0.0163, Train R2: 0.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6842, Val RMSE:   0.0139, Val R2:   0.0387\n",
      "No improvement. Patience: 1/50\n",
      "Epoch 7/500 completed in 50.76s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9447, Train RMSE: 0.0165, Train R2: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6707, Val RMSE:   0.0138, Val R2:   0.0586\n",
      "No improvement. Patience: 2/50\n",
      "Epoch 8/500 completed in 50.60s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9222, Train RMSE: 0.0162, Train R2: 0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6588, Val RMSE:   0.0136, Val R2:   0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 17:35:31,116 - INFO - Saved current checkpoint to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/checkpoints/checkpoint.pth.tar\n",
      "2025-05-07 17:35:40,211 - INFO - Saved new best model to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/checkpoints/model_best.pth.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 9 with val_loss 0.6588\n",
      "Epoch 9/500 completed in 70.51s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9008, Train RMSE: 0.0162, Train R2: 0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6683, Val RMSE:   0.0138, Val R2:   0.0558\n",
      "No improvement. Patience: 1/50\n",
      "Epoch 10/500 completed in 50.53s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8849, Train RMSE: 0.0159, Train R2: 0.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6706, Val RMSE:   0.0138, Val R2:   0.0568\n",
      "No improvement. Patience: 2/50\n",
      "Epoch 11/500 completed in 50.61s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8534, Train RMSE: 0.0157, Train R2: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6453, Val RMSE:   0.0135, Val R2:   0.0915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 17:38:22,886 - INFO - Saved current checkpoint to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/checkpoints/checkpoint.pth.tar\n",
      "2025-05-07 17:38:32,054 - INFO - Saved new best model to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/checkpoints/model_best.pth.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 12 with val_loss 0.6453\n",
      "Epoch 12/500 completed in 70.71s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8827, Train RMSE: 0.0159, Train R2: 0.1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6691, Val RMSE:   0.0138, Val R2:   0.0587\n",
      "No improvement. Patience: 1/50\n",
      "Epoch 13/500 completed in 50.73s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8502, Train RMSE: 0.0156, Train R2: 0.1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6685, Val RMSE:   0.0138, Val R2:   0.0574\n",
      "No improvement. Patience: 2/50\n",
      "Epoch 14/500 completed in 50.61s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8784, Train RMSE: 0.0159, Train R2: 0.1164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6486, Val RMSE:   0.0136, Val R2:   0.0859\n",
      "No improvement. Patience: 3/50\n",
      "Epoch 15/500 completed in 50.47s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8263, Train RMSE: 0.0155, Train R2: 0.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6629, Val RMSE:   0.0137, Val R2:   0.0607\n",
      "No improvement. Patience: 4/50\n",
      "Epoch 16/500 completed in 50.65s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8756, Train RMSE: 0.0160, Train R2: 0.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6736, Val RMSE:   0.0138, Val R2:   0.0513\n",
      "No improvement. Patience: 5/50\n",
      "Epoch 17/500 completed in 50.54s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8779, Train RMSE: 0.0160, Train R2: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6594, Val RMSE:   0.0137, Val R2:   0.0706\n",
      "No improvement. Patience: 6/50\n",
      "Epoch 18/500 completed in 50.47s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8474, Train RMSE: 0.0154, Train R2: 0.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6515, Val RMSE:   0.0136, Val R2:   0.0809\n",
      "No improvement. Patience: 7/50\n",
      "Epoch 19/500 completed in 50.71s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8668, Train RMSE: 0.0156, Train R2: 0.1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6539, Val RMSE:   0.0136, Val R2:   0.0774\n",
      "No improvement. Patience: 8/50\n",
      "Epoch 20/500 completed in 50.76s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8501, Train RMSE: 0.0157, Train R2: 0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6717, Val RMSE:   0.0138, Val R2:   0.0560\n",
      "No improvement. Patience: 9/50\n",
      "Epoch 21/500 completed in 50.84s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8473, Train RMSE: 0.0157, Train R2: 0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6683, Val RMSE:   0.0137, Val R2:   0.0612\n",
      "No improvement. Patience: 10/50\n",
      "Epoch 22/500 completed in 50.81s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8600, Train RMSE: 0.0157, Train R2: 0.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6572, Val RMSE:   0.0136, Val R2:   0.0773\n",
      "No improvement. Patience: 11/50\n",
      "Epoch 23/500 completed in 50.61s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8649, Train RMSE: 0.0156, Train R2: 0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6869, Val RMSE:   0.0139, Val R2:   0.0349\n",
      "No improvement. Patience: 12/50\n",
      "Epoch 24/500 completed in 50.64s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8568, Train RMSE: 0.0156, Train R2: 0.1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6744, Val RMSE:   0.0138, Val R2:   0.0532\n",
      "No improvement. Patience: 13/50\n",
      "Epoch 25/500 completed in 50.62s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8285, Train RMSE: 0.0155, Train R2: 0.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6756, Val RMSE:   0.0138, Val R2:   0.0485\n",
      "No improvement. Patience: 14/50\n",
      "Epoch 26/500 completed in 50.57s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7909, Train RMSE: 0.0149, Train R2: 0.2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6763, Val RMSE:   0.0138, Val R2:   0.0478\n",
      "No improvement. Patience: 15/50\n",
      "Epoch 27/500 completed in 50.48s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8305, Train RMSE: 0.0154, Train R2: 0.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6667, Val RMSE:   0.0137, Val R2:   0.0626\n",
      "No improvement. Patience: 16/50\n",
      "Epoch 28/500 completed in 50.66s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7970, Train RMSE: 0.0153, Train R2: 0.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6790, Val RMSE:   0.0139, Val R2:   0.0444\n",
      "No improvement. Patience: 17/50\n",
      "Epoch 29/500 completed in 50.68s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8242, Train RMSE: 0.0154, Train R2: 0.1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6710, Val RMSE:   0.0138, Val R2:   0.0571\n",
      "No improvement. Patience: 18/50\n",
      "Epoch 30/500 completed in 50.54s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8178, Train RMSE: 0.0154, Train R2: 0.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6770, Val RMSE:   0.0139, Val R2:   0.0453\n",
      "No improvement. Patience: 19/50\n",
      "Epoch 31/500 completed in 50.74s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8330, Train RMSE: 0.0154, Train R2: 0.1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6868, Val RMSE:   0.0139, Val R2:   0.0333\n",
      "No improvement. Patience: 20/50\n",
      "Epoch 32/500 completed in 50.68s\n",
      "Current LR: 5.00e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8304, Train RMSE: 0.0153, Train R2: 0.1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6812, Val RMSE:   0.0139, Val R2:   0.0407\n",
      "No improvement. Patience: 21/50\n",
      "Epoch 33/500 completed in 50.63s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7572, Train RMSE: 0.0148, Train R2: 0.2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6766, Val RMSE:   0.0138, Val R2:   0.0480\n",
      "No improvement. Patience: 22/50\n",
      "Epoch 34/500 completed in 50.51s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7891, Train RMSE: 0.0149, Train R2: 0.2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6842, Val RMSE:   0.0139, Val R2:   0.0398\n",
      "No improvement. Patience: 23/50\n",
      "Epoch 35/500 completed in 50.58s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7616, Train RMSE: 0.0148, Train R2: 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6756, Val RMSE:   0.0138, Val R2:   0.0500\n",
      "No improvement. Patience: 24/50\n",
      "Epoch 36/500 completed in 50.68s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8078, Train RMSE: 0.0152, Train R2: 0.1886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6709, Val RMSE:   0.0138, Val R2:   0.0548\n",
      "No improvement. Patience: 25/50\n",
      "Epoch 37/500 completed in 50.50s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8220, Train RMSE: 0.0153, Train R2: 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6625, Val RMSE:   0.0137, Val R2:   0.0679\n",
      "No improvement. Patience: 26/50\n",
      "Epoch 38/500 completed in 50.62s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7697, Train RMSE: 0.0149, Train R2: 0.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6711, Val RMSE:   0.0138, Val R2:   0.0547\n",
      "No improvement. Patience: 27/50\n",
      "Epoch 39/500 completed in 50.54s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7403, Train RMSE: 0.0147, Train R2: 0.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6818, Val RMSE:   0.0139, Val R2:   0.0429\n",
      "No improvement. Patience: 28/50\n",
      "Epoch 40/500 completed in 50.71s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7708, Train RMSE: 0.0148, Train R2: 0.2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6715, Val RMSE:   0.0138, Val R2:   0.0565\n",
      "No improvement. Patience: 29/50\n",
      "Epoch 41/500 completed in 50.61s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7251, Train RMSE: 0.0146, Train R2: 0.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6835, Val RMSE:   0.0139, Val R2:   0.0365\n",
      "No improvement. Patience: 30/50\n",
      "Epoch 42/500 completed in 50.59s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7656, Train RMSE: 0.0145, Train R2: 0.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6670, Val RMSE:   0.0137, Val R2:   0.0613\n",
      "No improvement. Patience: 31/50\n",
      "Epoch 43/500 completed in 50.68s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7674, Train RMSE: 0.0146, Train R2: 0.2491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6675, Val RMSE:   0.0138, Val R2:   0.0597\n",
      "No improvement. Patience: 32/50\n",
      "Epoch 44/500 completed in 50.62s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7313, Train RMSE: 0.0144, Train R2: 0.2726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6737, Val RMSE:   0.0138, Val R2:   0.0512\n",
      "No improvement. Patience: 33/50\n",
      "Epoch 45/500 completed in 50.57s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7060, Train RMSE: 0.0145, Train R2: 0.2662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6756, Val RMSE:   0.0139, Val R2:   0.0421\n",
      "No improvement. Patience: 34/50\n",
      "Epoch 46/500 completed in 50.53s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7343, Train RMSE: 0.0147, Train R2: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6609, Val RMSE:   0.0137, Val R2:   0.0671\n",
      "No improvement. Patience: 35/50\n",
      "Epoch 47/500 completed in 50.48s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8020, Train RMSE: 0.0149, Train R2: 0.2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6873, Val RMSE:   0.0140, Val R2:   0.0310\n",
      "No improvement. Patience: 36/50\n",
      "Epoch 48/500 completed in 50.51s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7290, Train RMSE: 0.0143, Train R2: 0.2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6650, Val RMSE:   0.0137, Val R2:   0.0626\n",
      "No improvement. Patience: 37/50\n",
      "Epoch 49/500 completed in 50.50s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7411, Train RMSE: 0.0147, Train R2: 0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6724, Val RMSE:   0.0138, Val R2:   0.0543\n",
      "No improvement. Patience: 38/50\n",
      "Epoch 50/500 completed in 50.74s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6958, Train RMSE: 0.0141, Train R2: 0.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6729, Val RMSE:   0.0138, Val R2:   0.0511\n",
      "No improvement. Patience: 39/50\n",
      "Epoch 51/500 completed in 50.79s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6786, Train RMSE: 0.0140, Train R2: 0.3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6586, Val RMSE:   0.0137, Val R2:   0.0710\n",
      "No improvement. Patience: 40/50\n",
      "Epoch 52/500 completed in 50.54s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7029, Train RMSE: 0.0144, Train R2: 0.2675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6783, Val RMSE:   0.0139, Val R2:   0.0448\n",
      "No improvement. Patience: 41/50\n",
      "Epoch 53/500 completed in 50.66s\n",
      "Current LR: 2.50e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7204, Train RMSE: 0.0144, Train R2: 0.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6550, Val RMSE:   0.0136, Val R2:   0.0774\n",
      "No improvement. Patience: 42/50\n",
      "Epoch 54/500 completed in 50.74s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7118, Train RMSE: 0.0143, Train R2: 0.2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6713, Val RMSE:   0.0138, Val R2:   0.0553\n",
      "No improvement. Patience: 43/50\n",
      "Epoch 55/500 completed in 50.63s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7024, Train RMSE: 0.0142, Train R2: 0.2879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6732, Val RMSE:   0.0138, Val R2:   0.0512\n",
      "No improvement. Patience: 44/50\n",
      "Epoch 56/500 completed in 50.48s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7145, Train RMSE: 0.0141, Train R2: 0.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6858, Val RMSE:   0.0139, Val R2:   0.0335\n",
      "No improvement. Patience: 45/50\n",
      "Epoch 57/500 completed in 50.66s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7473, Train RMSE: 0.0145, Train R2: 0.2634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6675, Val RMSE:   0.0137, Val R2:   0.0612\n",
      "No improvement. Patience: 46/50\n",
      "Epoch 58/500 completed in 50.59s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7183, Train RMSE: 0.0141, Train R2: 0.3007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6574, Val RMSE:   0.0137, Val R2:   0.0709\n",
      "No improvement. Patience: 47/50\n",
      "Epoch 59/500 completed in 50.64s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7177, Train RMSE: 0.0142, Train R2: 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6894, Val RMSE:   0.0140, Val R2:   0.0274\n",
      "No improvement. Patience: 48/50\n",
      "Epoch 60/500 completed in 50.76s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6520, Train RMSE: 0.0138, Train R2: 0.3348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6734, Val RMSE:   0.0138, Val R2:   0.0486\n",
      "No improvement. Patience: 49/50\n",
      "Epoch 61/500 completed in 50.64s\n",
      "Current LR: 1.25e-05\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6721, Train RMSE: 0.0138, Train R2: 0.3313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:   0.6631, Val RMSE:   0.0137, Val R2:   0.0663\n",
      "No improvement. Patience: 50/50\n",
      "Early stopping triggered after 62 epochs\n",
      "Training complete!\n",
      "Best validation loss: 0.6453, Best R2: 0.0915\n",
      "Final model saved to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/checkpoints/final_model.pt\n",
      "Training log saved to /home/jupyter/MLC-Project/training_runs/BranchedUHIModel_NYC_unet_20250507_172717/training_log.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>lr</td><td>███████████████████████▃▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▆▅▅▄▅▅▅▄▄▄▄▄▄▃▄▄▄▂▃▃▂▂▃▂▂▃▂▂▁▂▂▂▂▂▁</td></tr><tr><td>train_r2</td><td>▁▂▂▃▃▃▄▄▄▅▅▅▄▄▅▅▅▅▆▅▅▅▅▆▆▆▆▇▇▇▆▇▆▇▇▇▇▇▇█</td></tr><tr><td>train_rmse</td><td>█▇▇▇▆▆▅▅▅▄▄▅▄▅▅▄▄▄▃▄▄▄▄▄▃▃▃▂▃▂▂▃▂▁▂▂▂▂▂▁</td></tr><tr><td>val_loss</td><td>█▇▅▃▂▃▂▃▃▁▃▂▁▁▃▂▃▄▄▄▅▄▃▂▃▃▄▃▄▂▃▃▂▄▂▄▃▂▅▂</td></tr><tr><td>val_r2</td><td>▁▂▄▆▇▅▆▇▆▆▆█▇▆▆▅▆▆▆▅▅▅▆▅▆▇▆▅▆▅▆▆▇▇▆▇▅▆▅▆</td></tr><tr><td>val_rmse</td><td>█▇▃▂▃▃▂▃▃▁▃▂▁▂▃▂▄▃▃▄▄▄▃▄▃▄▃▄▃▃▄▄▂▃▃▃▄▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>62</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.67213</td></tr><tr><td>train_r2</td><td>0.33128</td></tr><tr><td>train_rmse</td><td>0.0138</td></tr><tr><td>val_loss</td><td>0.66309</td></tr><tr><td>val_r2</td><td>0.06632</td></tr><tr><td>val_rmse</td><td>0.01371</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">NYC_BranchedUHI_20250507_1727</strong> at: <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/w8xg7pex' target=\"_blank\">https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj/runs/w8xg7pex</a><br> View project at: <a href='https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj' target=\"_blank\">https://wandb.ai/arnava1304-columbia-university/MLC_UHI_Proj</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250507_172729-w8xg7pex/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% Training Loop (Branched Model)\n",
    "\n",
    "# --- Helper functions ---\n",
    "# Get the warmup epochs from config or default to 5\n",
    "warmup_epochs = config.get(\"warmup_epochs\", 5)\n",
    "\n",
    "# --- Training Loop ---\n",
    "# Initialize metrics tracking\n",
    "best_val_loss = float('inf')\n",
    "best_val_r2 = -float('inf')\n",
    "patience_counter = 0\n",
    "training_log = []\n",
    "\n",
    "# Create run directory\n",
    "model_save_dir = Path(config['run_dir']) / \"checkpoints\"\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save config to run directory\n",
    "config_path = Path(config['run_dir']) / \"config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2, default=lambda x: str(x) if isinstance(x, (Path, torch.device)) else x)\n",
    "\n",
    "# Initialize wandb\n",
    "try:\n",
    "    import wandb\n",
    "    wandb_available = True\n",
    "    print(\"Weights & Biases (wandb) available for logging.\")\n",
    "except ImportError:\n",
    "    wandb_available = False\n",
    "    wandb = None\n",
    "    print(\"Weights & Biases (wandb) not available. Skipping wandb logging.\")\n",
    "\n",
    "if wandb_available:\n",
    "    # Configure wandb\n",
    "    wandb.init(\n",
    "        project=config['wandb_project_name'],\n",
    "        name=f\"{config['wander_run_name_prefix']}_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Optional: watch model parameters\n",
    "    wandb.watch(model)\n",
    "\n",
    "print(f\"Starting training for {config['epochs']} epochs with patience {config['patience']}\")\n",
    "\n",
    "try:\n",
    "    for epoch in range(config['epochs']):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # --- Train --- #\n",
    "        if train_loader:\n",
    "            # Use generic train function from train_utils\n",
    "            train_loss, train_rmse, train_r2 = train_utils.train_epoch_generic(\n",
    "                model, train_loader, optimizer, loss_fn, device, \n",
    "                uhi_mean=config['uhi_mean'], \n",
    "                uhi_std=config['uhi_std'],\n",
    "                feature_flags=config['feature_flags'],\n",
    "                max_grad_norm=config.get(\"max_grad_norm\", 1.0)\n",
    "            )\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train RMSE: {train_rmse:.4f}, Train R2: {train_r2:.4f}\")\n",
    "            if np.isnan(train_loss):\n",
    "                print(\"Warning: Training loss is NaN. Stopping training.\")\n",
    "                break\n",
    "            log_metrics = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_rmse\": train_rmse, \"train_r2\": train_r2}\n",
    "        else:\n",
    "            print(\"Skipping training: train_loader is None.\")\n",
    "            train_loss, train_rmse, train_r2 = float('nan'), float('nan'), float('nan')\n",
    "            log_metrics = {\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_rmse\": train_rmse, \"train_r2\": train_r2}\n",
    "        \n",
    "        # Log train metrics AFTER checking for NaN\n",
    "        if wandb:\n",
    "            wandb.log(log_metrics)\n",
    "        training_log.append(log_metrics) # Append to local log regardless of W&B\n",
    "\n",
    "\n",
    "        # --- Validate --- #\n",
    "        if val_loader:\n",
    "            # Use generic validate function from train_utils\n",
    "            val_loss, val_rmse, val_r2 = train_utils.validate_epoch_generic(\n",
    "                model, val_loader, loss_fn, device, \n",
    "                uhi_mean=config['uhi_mean'], \n",
    "                uhi_std=config['uhi_std'],\n",
    "                feature_flags=config['feature_flags']\n",
    "            )\n",
    "            print(f\"Val Loss:   {val_loss:.4f}, Val RMSE:   {val_rmse:.4f}, Val R2:   {val_r2:.4f}\")\n",
    "            if np.isnan(val_loss):\n",
    "                print(\"Warning: Validation Loss is NaN. Stopping training.\")\n",
    "                break\n",
    "            val_metrics = {\"val_loss\": val_loss, \"val_rmse\": val_rmse, \"val_r2\": val_r2}\n",
    "            log_metrics.update(val_metrics)\n",
    "            \n",
    "            # Log validation metrics\n",
    "            if wandb:\n",
    "                wandb.log(val_metrics)\n",
    "            \n",
    "            # Warmup period: don't save or check early stopping until after warmup_epochs\n",
    "            if epoch >= warmup_epochs:\n",
    "                # Check for improvement (using validation loss now)\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_val_r2 = val_r2\n",
    "                    patience_counter = 0\n",
    "                    \n",
    "                    # Save best model\n",
    "                    train_utils.save_checkpoint({\n",
    "                        'epoch': epoch + 1,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'scheduler': scheduler.state_dict() if scheduler else None,\n",
    "                        'loss': val_loss,\n",
    "                        'val_rmse': val_rmse,\n",
    "                        'val_r2': val_r2,\n",
    "                        'config': config\n",
    "                    }, is_best=True, output_dir=model_save_dir)\n",
    "                    print(f\"New best model saved at epoch {epoch+1} with val_loss {val_loss:.4f}\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    print(f\"No improvement. Patience: {patience_counter}/{config['patience']}\")\n",
    "                    \n",
    "                    # Early stopping check\n",
    "                    if patience_counter >= config['patience']:\n",
    "                        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                        break\n",
    "            else:\n",
    "                print(f\"Warmup epoch {epoch+1}/{warmup_epochs}. Skipping checkpointing and early stopping.\")\n",
    "        else:\n",
    "            print(\"Skipping validation: val_loader is None.\")\n",
    "            \n",
    "        # Step the scheduler after validation (if it exists)\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            if wandb:\n",
    "                wandb.log({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "                \n",
    "        # Print epoch summary\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1}/{config['epochs']} completed in {epoch_time:.2f}s\")\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        print(\"-\" * 80)\n",
    "            \n",
    "    print(\"Training complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}, Best R2: {best_val_r2:.4f}\")\n",
    "    \n",
    "    # Save the final model\n",
    "    final_model_path = model_save_dir / \"final_model.pt\"\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'config': config\n",
    "    }, final_model_path)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "    \n",
    "    # Save training log\n",
    "    log_df = pd.DataFrame(training_log)\n",
    "    log_path = Path(config['run_dir']) / \"training_log.csv\"\n",
    "    log_df.to_csv(log_path, index=False)\n",
    "    print(f\"Training log saved to {log_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {str(e)}\")\n",
    "    raise\n",
    "finally:\n",
    "    # Finish wandb run\n",
    "    if wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930bc3f7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
